<!doctype html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />

    <title>noxer.nn API documentation</title>
    <meta name="description" content="" />

  <link href='http://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300' rel='stylesheet' type='text/css'>
  
  <style type="text/css">
  
* {
  box-sizing: border-box;
}
/*! normalize.css v1.1.1 | MIT License | git.io/normalize */

/* ==========================================================================
   HTML5 display definitions
   ========================================================================== */

/**
 * Correct `block` display not defined in IE 6/7/8/9 and Firefox 3.
 */

article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
nav,
section,
summary {
    display: block;
}

/**
 * Correct `inline-block` display not defined in IE 6/7/8/9 and Firefox 3.
 */

audio,
canvas,
video {
    display: inline-block;
    *display: inline;
    *zoom: 1;
}

/**
 * Prevent modern browsers from displaying `audio` without controls.
 * Remove excess height in iOS 5 devices.
 */

audio:not([controls]) {
    display: none;
    height: 0;
}

/**
 * Address styling not present in IE 7/8/9, Firefox 3, and Safari 4.
 * Known issue: no IE 6 support.
 */

[hidden] {
    display: none;
}

/* ==========================================================================
   Base
   ========================================================================== */

/**
 * 1. Prevent system color scheme's background color being used in Firefox, IE,
 *    and Opera.
 * 2. Prevent system color scheme's text color being used in Firefox, IE, and
 *    Opera.
 * 3. Correct text resizing oddly in IE 6/7 when body `font-size` is set using
 *    `em` units.
 * 4. Prevent iOS text size adjust after orientation change, without disabling
 *    user zoom.
 */

html {
    background: #fff; /* 1 */
    color: #000; /* 2 */
    font-size: 100%; /* 3 */
    -webkit-text-size-adjust: 100%; /* 4 */
    -ms-text-size-adjust: 100%; /* 4 */
}

/**
 * Address `font-family` inconsistency between `textarea` and other form
 * elements.
 */

html,
button,
input,
select,
textarea {
    font-family: sans-serif;
}

/**
 * Address margins handled incorrectly in IE 6/7.
 */

body {
    margin: 0;
}

/* ==========================================================================
   Links
   ========================================================================== */

/**
 * Address `outline` inconsistency between Chrome and other browsers.
 */

a:focus {
    outline: thin dotted;
}

/**
 * Improve readability when focused and also mouse hovered in all browsers.
 */

a:active,
a:hover {
    outline: 0;
}

/* ==========================================================================
   Typography
   ========================================================================== */

/**
 * Address font sizes and margins set differently in IE 6/7.
 * Address font sizes within `section` and `article` in Firefox 4+, Safari 5,
 * and Chrome.
 */

h1 {
    font-size: 2em;
    margin: 0.67em 0;
}

h2 {
    font-size: 1.5em;
    margin: 0.83em 0;
}

h3 {
    font-size: 1.17em;
    margin: 1em 0;
}

h4 {
    font-size: 1em;
    margin: 1.33em 0;
}

h5 {
    font-size: 0.83em;
    margin: 1.67em 0;
}

h6 {
    font-size: 0.67em;
    margin: 2.33em 0;
}

/**
 * Address styling not present in IE 7/8/9, Safari 5, and Chrome.
 */

abbr[title] {
    border-bottom: 1px dotted;
}

/**
 * Address style set to `bolder` in Firefox 3+, Safari 4/5, and Chrome.
 */

b,
strong {
    font-weight: bold;
}

blockquote {
    margin: 1em 40px;
}

/**
 * Address styling not present in Safari 5 and Chrome.
 */

dfn {
    font-style: italic;
}

/**
 * Address differences between Firefox and other browsers.
 * Known issue: no IE 6/7 normalization.
 */

hr {
    -moz-box-sizing: content-box;
    box-sizing: content-box;
    height: 0;
}

/**
 * Address styling not present in IE 6/7/8/9.
 */

mark {
    background: #ff0;
    color: #000;
}

/**
 * Address margins set differently in IE 6/7.
 */

p,
pre {
    margin: 1em 0;
}

/**
 * Correct font family set oddly in IE 6, Safari 4/5, and Chrome.
 */

code,
kbd,
pre,
samp {
    font-family: monospace, serif;
    _font-family: 'courier new', monospace;
    font-size: 1em;
}

/**
 * Improve readability of pre-formatted text in all browsers.
 */

pre {
    white-space: pre;
    white-space: pre-wrap;
    word-wrap: break-word;
}

/**
 * Address CSS quotes not supported in IE 6/7.
 */

q {
    quotes: none;
}

/**
 * Address `quotes` property not supported in Safari 4.
 */

q:before,
q:after {
    content: '';
    content: none;
}

/**
 * Address inconsistent and variable font size in all browsers.
 */

small {
    font-size: 80%;
}

/**
 * Prevent `sub` and `sup` affecting `line-height` in all browsers.
 */

sub,
sup {
    font-size: 75%;
    line-height: 0;
    position: relative;
    vertical-align: baseline;
}

sup {
    top: -0.5em;
}

sub {
    bottom: -0.25em;
}

/* ==========================================================================
   Lists
   ========================================================================== */

/**
 * Address margins set differently in IE 6/7.
 */

dl,
menu,
ol,
ul {
    margin: 1em 0;
}

dd {
    margin: 0 0 0 40px;
}

/**
 * Address paddings set differently in IE 6/7.
 */

menu,
ol,
ul {
    padding: 0 0 0 40px;
}

/**
 * Correct list images handled incorrectly in IE 7.
 */

nav ul,
nav ol {
    list-style: none;
    list-style-image: none;
}

/* ==========================================================================
   Embedded content
   ========================================================================== */

/**
 * 1. Remove border when inside `a` element in IE 6/7/8/9 and Firefox 3.
 * 2. Improve image quality when scaled in IE 7.
 */

img {
    border: 0; /* 1 */
    -ms-interpolation-mode: bicubic; /* 2 */
}

/**
 * Correct overflow displayed oddly in IE 9.
 */

svg:not(:root) {
    overflow: hidden;
}

/* ==========================================================================
   Figures
   ========================================================================== */

/**
 * Address margin not present in IE 6/7/8/9, Safari 5, and Opera 11.
 */

figure {
    margin: 0;
}

/* ==========================================================================
   Forms
   ========================================================================== */

/**
 * Correct margin displayed oddly in IE 6/7.
 */

form {
    margin: 0;
}

/**
 * Define consistent border, margin, and padding.
 */

fieldset {
    border: 1px solid #c0c0c0;
    margin: 0 2px;
    padding: 0.35em 0.625em 0.75em;
}

/**
 * 1. Correct color not being inherited in IE 6/7/8/9.
 * 2. Correct text not wrapping in Firefox 3.
 * 3. Correct alignment displayed oddly in IE 6/7.
 */

legend {
    border: 0; /* 1 */
    padding: 0;
    white-space: normal; /* 2 */
    *margin-left: -7px; /* 3 */
}

/**
 * 1. Correct font size not being inherited in all browsers.
 * 2. Address margins set differently in IE 6/7, Firefox 3+, Safari 5,
 *    and Chrome.
 * 3. Improve appearance and consistency in all browsers.
 */

button,
input,
select,
textarea {
    font-size: 100%; /* 1 */
    margin: 0; /* 2 */
    vertical-align: baseline; /* 3 */
    *vertical-align: middle; /* 3 */
}

/**
 * Address Firefox 3+ setting `line-height` on `input` using `!important` in
 * the UA stylesheet.
 */

button,
input {
    line-height: normal;
}

/**
 * Address inconsistent `text-transform` inheritance for `button` and `select`.
 * All other form control elements do not inherit `text-transform` values.
 * Correct `button` style inheritance in Chrome, Safari 5+, and IE 6+.
 * Correct `select` style inheritance in Firefox 4+ and Opera.
 */

button,
select {
    text-transform: none;
}

/**
 * 1. Avoid the WebKit bug in Android 4.0.* where (2) destroys native `audio`
 *    and `video` controls.
 * 2. Correct inability to style clickable `input` types in iOS.
 * 3. Improve usability and consistency of cursor style between image-type
 *    `input` and others.
 * 4. Remove inner spacing in IE 7 without affecting normal text inputs.
 *    Known issue: inner spacing remains in IE 6.
 */

button,
html input[type="button"], /* 1 */
input[type="reset"],
input[type="submit"] {
    -webkit-appearance: button; /* 2 */
    cursor: pointer; /* 3 */
    *overflow: visible;  /* 4 */
}

/**
 * Re-set default cursor for disabled elements.
 */

button[disabled],
html input[disabled] {
    cursor: default;
}

/**
 * 1. Address box sizing set to content-box in IE 8/9.
 * 2. Remove excess padding in IE 8/9.
 * 3. Remove excess padding in IE 7.
 *    Known issue: excess padding remains in IE 6.
 */

input[type="checkbox"],
input[type="radio"] {
    box-sizing: border-box; /* 1 */
    padding: 0; /* 2 */
    *height: 13px; /* 3 */
    *width: 13px; /* 3 */
}

/**
 * 1. Address `appearance` set to `searchfield` in Safari 5 and Chrome.
 * 2. Address `box-sizing` set to `border-box` in Safari 5 and Chrome
 *    (include `-moz` to future-proof).
 */

input[type="search"] {
    -webkit-appearance: textfield; /* 1 */
    -moz-box-sizing: content-box;
    -webkit-box-sizing: content-box; /* 2 */
    box-sizing: content-box;
}

/**
 * Remove inner padding and search cancel button in Safari 5 and Chrome
 * on OS X.
 */

input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
    -webkit-appearance: none;
}

/**
 * Remove inner padding and border in Firefox 3+.
 */

button::-moz-focus-inner,
input::-moz-focus-inner {
    border: 0;
    padding: 0;
}

/**
 * 1. Remove default vertical scrollbar in IE 6/7/8/9.
 * 2. Improve readability and alignment in all browsers.
 */

textarea {
    overflow: auto; /* 1 */
    vertical-align: top; /* 2 */
}

/* ==========================================================================
   Tables
   ========================================================================== */

/**
 * Remove most spacing between table cells.
 */

table {
    border-collapse: collapse;
    border-spacing: 0;
}

  </style>

  <style type="text/css">
  
  html, body {
    margin: 0;
    padding: 0;
    min-height: 100%;
  }
  body {
    background: #fff;
    font-family: "Source Sans Pro", "Helvetica Neueue", Helvetica, sans;
    font-weight: 300;
    font-size: 16px;
    line-height: 1.6em;
  }
  #content {
    width: 70%;
    max-width: 850px;
    float: left;
    padding: 30px 60px;
    border-left: 1px solid #ddd;
  }
  #sidebar {
    width: 25%;
    float: left;
    padding: 30px;
    overflow: hidden;
  }
  #nav {
    font-size: 130%;
    margin: 0 0 15px 0;
  }

  #top {
    display: block;
    position: fixed;
    bottom: 5px;
    left: 5px;
    font-size: .85em;
    text-transform: uppercase;
  }

  #footer {
    font-size: .75em;
    padding: 5px 30px;
    border-top: 1px solid #ddd;
    text-align: right;
  }
    #footer p {
      margin: 0 0 0 30px;
      display: inline-block;
    }

  h1, h2, h3, h4, h5 {
    font-weight: 300;
  }
  h1 {
    font-size: 2.5em;
    line-height: 1.1em;
    margin: 0 0 .50em 0;
  }

  h2 {
    font-size: 1.75em;
    margin: 1em 0 .50em 0;
  }

  h3 {
    margin: 25px 0 10px 0;
  }

  h4 {
    margin: 0;
    font-size: 105%;
  }

  a {
    color: #058;
    text-decoration: none;
    transition: color .3s ease-in-out;
  }

  a:hover {
    color: #e08524;
    transition: color .3s ease-in-out;
  }

  pre, code, .mono, .name {
    font-family: "Ubuntu Mono", "Cousine", "DejaVu Sans Mono", monospace;
  }

  .title .name {
    font-weight: bold;
  }
  .section-title {
    margin-top: 2em;
  }
  .ident {
    color: #900;
  }

  code {
    background: #f9f9f9;
  } 

  pre {
    background: #fefefe;
    border: 1px solid #ddd;
    box-shadow: 2px 2px 0 #f3f3f3;
    margin: 0 30px;
    padding: 15px 30px;
  }

  .codehilite {
    margin: 0 30px 10px 30px;
  }

    .codehilite pre {
      margin: 0;
    }
    .codehilite .err { background: #ff3300; color: #fff !important; } 

  table#module-list {
    font-size: 110%;
  }

    table#module-list tr td:first-child {
      padding-right: 10px;
      white-space: nowrap;
    }

    table#module-list td {
      vertical-align: top;
      padding-bottom: 8px;
    }

      table#module-list td p {
        margin: 0 0 7px 0;
      }

  .def {
    display: table;
  }

    .def p {
      display: table-cell;
      vertical-align: top;
      text-align: left;
    }

    .def p:first-child {
      white-space: nowrap;
    }

    .def p:last-child {
      width: 100%;
    }


  #index {
    list-style-type: none;
    margin: 0;
    padding: 0;
  }
    ul#index .class_name {
      /* font-size: 110%; */
      font-weight: bold;
    }
    #index ul {
      margin: 0;
    }

  .item {
    margin: 0 0 15px 0;
  }

    .item .class {
      margin: 0 0 25px 30px;
    }

      .item .class ul.class_list {
        margin: 0 0 20px 0;
      }

    .item .name {
      background: #fafafa;
      margin: 0;
      font-weight: bold;
      padding: 5px 10px;
      border-radius: 3px;
      display: inline-block;
      min-width: 40%;
    }
      .item .name:hover {
        background: #f6f6f6;
      }

    .item .empty_desc {
      margin: 0 0 5px 0;
      padding: 0;
    }

    .item .inheritance {
      margin: 3px 0 0 30px;
    }

    .item .inherited {
      color: #666;
    }

    .item .desc {
      padding: 0 8px;
      margin: 0;
    }

      .item .desc p {
        margin: 0 0 10px 0;
      }

    .source_cont {
      margin: 0;
      padding: 0;
    }

    .source_link a {
      background: #ffc300;
      font-weight: 400;
      font-size: .75em;
      text-transform: uppercase;
      color: #fff;
      text-shadow: 1px 1px 0 #f4b700;
      
      padding: 3px 8px;
      border-radius: 2px;
      transition: background .3s ease-in-out;
    }
      .source_link a:hover {
        background: #FF7200;
        text-shadow: none;
        transition: background .3s ease-in-out;
      }

    .source {
      display: none;
      max-height: 600px;
      overflow-y: scroll;
      margin-bottom: 15px;
    }

      .source .codehilite {
        margin: 0;
      }

  .desc h1, .desc h2, .desc h3 {
    font-size: 100% !important;
  }
  .clear {
    clear: both;
  }

  @media all and (max-width: 950px) {
    #sidebar {
      width: 35%;
    }
    #content {
      width: 65%;
    }
  }
  @media all and (max-width: 650px) {
    #top {
      display: none;
    }
    #sidebar {
      float: none;
      width: auto;
    }
    #content {
      float: none;
      width: auto;
      padding: 30px;
    }

    #index ul {
      padding: 0;
      margin-bottom: 15px;
    }
    #index ul li {
      display: inline-block;
      margin-right: 30px;
    }
    #footer {
      text-align: left;
    }
    #footer p {
      display: block;
      margin: inherit;
    }
  }

  /*****************************/

  </style>

  <style type="text/css">
  .codehilite .hll { background-color: #ffffcc }
.codehilite  { background: #f8f8f8; }
.codehilite .c { color: #408080; font-style: italic } /* Comment */
.codehilite .err { border: 1px solid #FF0000 } /* Error */
.codehilite .k { color: #008000; font-weight: bold } /* Keyword */
.codehilite .o { color: #666666 } /* Operator */
.codehilite .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.codehilite .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.codehilite .cp { color: #BC7A00 } /* Comment.Preproc */
.codehilite .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.codehilite .c1 { color: #408080; font-style: italic } /* Comment.Single */
.codehilite .cs { color: #408080; font-style: italic } /* Comment.Special */
.codehilite .gd { color: #A00000 } /* Generic.Deleted */
.codehilite .ge { font-style: italic } /* Generic.Emph */
.codehilite .gr { color: #FF0000 } /* Generic.Error */
.codehilite .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.codehilite .gi { color: #00A000 } /* Generic.Inserted */
.codehilite .go { color: #888888 } /* Generic.Output */
.codehilite .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.codehilite .gs { font-weight: bold } /* Generic.Strong */
.codehilite .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.codehilite .gt { color: #0044DD } /* Generic.Traceback */
.codehilite .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.codehilite .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.codehilite .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.codehilite .kp { color: #008000 } /* Keyword.Pseudo */
.codehilite .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.codehilite .kt { color: #B00040 } /* Keyword.Type */
.codehilite .m { color: #666666 } /* Literal.Number */
.codehilite .s { color: #BA2121 } /* Literal.String */
.codehilite .na { color: #7D9029 } /* Name.Attribute */
.codehilite .nb { color: #008000 } /* Name.Builtin */
.codehilite .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.codehilite .no { color: #880000 } /* Name.Constant */
.codehilite .nd { color: #AA22FF } /* Name.Decorator */
.codehilite .ni { color: #999999; font-weight: bold } /* Name.Entity */
.codehilite .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.codehilite .nf { color: #0000FF } /* Name.Function */
.codehilite .nl { color: #A0A000 } /* Name.Label */
.codehilite .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.codehilite .nt { color: #008000; font-weight: bold } /* Name.Tag */
.codehilite .nv { color: #19177C } /* Name.Variable */
.codehilite .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.codehilite .w { color: #bbbbbb } /* Text.Whitespace */
.codehilite .mb { color: #666666 } /* Literal.Number.Bin */
.codehilite .mf { color: #666666 } /* Literal.Number.Float */
.codehilite .mh { color: #666666 } /* Literal.Number.Hex */
.codehilite .mi { color: #666666 } /* Literal.Number.Integer */
.codehilite .mo { color: #666666 } /* Literal.Number.Oct */
.codehilite .sa { color: #BA2121 } /* Literal.String.Affix */
.codehilite .sb { color: #BA2121 } /* Literal.String.Backtick */
.codehilite .sc { color: #BA2121 } /* Literal.String.Char */
.codehilite .dl { color: #BA2121 } /* Literal.String.Delimiter */
.codehilite .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.codehilite .s2 { color: #BA2121 } /* Literal.String.Double */
.codehilite .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.codehilite .sh { color: #BA2121 } /* Literal.String.Heredoc */
.codehilite .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.codehilite .sx { color: #008000 } /* Literal.String.Other */
.codehilite .sr { color: #BB6688 } /* Literal.String.Regex */
.codehilite .s1 { color: #BA2121 } /* Literal.String.Single */
.codehilite .ss { color: #19177C } /* Literal.String.Symbol */
.codehilite .bp { color: #008000 } /* Name.Builtin.Pseudo */
.codehilite .fm { color: #0000FF } /* Name.Function.Magic */
.codehilite .vc { color: #19177C } /* Name.Variable.Class */
.codehilite .vg { color: #19177C } /* Name.Variable.Global */
.codehilite .vi { color: #19177C } /* Name.Variable.Instance */
.codehilite .vm { color: #19177C } /* Name.Variable.Magic */
.codehilite .il { color: #666666 } /* Literal.Number.Integer.Long */
  </style>

  <style type="text/css">
  
/* ==========================================================================
   EXAMPLE Media Queries for Responsive Design.
   These examples override the primary ('mobile first') styles.
   Modify as content requires.
   ========================================================================== */

@media only screen and (min-width: 35em) {
    /* Style adjustments for viewports that meet the condition */
}

@media print,
       (-o-min-device-pixel-ratio: 5/4),
       (-webkit-min-device-pixel-ratio: 1.25),
       (min-resolution: 120dpi) {
    /* Style adjustments for high resolution devices */
}

/* ==========================================================================
   Print styles.
   Inlined to avoid required HTTP connection: h5bp.com/r
   ========================================================================== */

@media print {
    * {
        background: transparent !important;
        color: #000 !important; /* Black prints faster: h5bp.com/s */
        box-shadow: none !important;
        text-shadow: none !important;
    }

    a,
    a:visited {
        text-decoration: underline;
    }

    a[href]:after {
        content: " (" attr(href) ")";
    }

    abbr[title]:after {
        content: " (" attr(title) ")";
    }

    /*
     * Don't show links for images, or javascript/internal links
     */

    .ir a:after,
    a[href^="javascript:"]:after,
    a[href^="#"]:after {
        content: "";
    }

    pre,
    blockquote {
        border: 1px solid #999;
        page-break-inside: avoid;
    }

    thead {
        display: table-header-group; /* h5bp.com/t */
    }

    tr,
    img {
        page-break-inside: avoid;
    }

    img {
        max-width: 100% !important;
    }

    @page {
        margin: 0.5cm;
    }

    p,
    h2,
    h3 {
        orphans: 3;
        widows: 3;
    }

    h2,
    h3 {
        page-break-after: avoid;
    }
}

  </style>

  <script type="text/javascript">
  function toggle(id, $link) {
    $node = document.getElementById(id);
    if (!$node)
    return;
    if (!$node.style.display || $node.style.display == 'none') {
    $node.style.display = 'block';
    $link.innerHTML = 'Hide source &nequiv;';
    } else {
    $node.style.display = 'none';
    $link.innerHTML = 'Show source &equiv;';
    }
  }
  </script>
</head>
<body>
<a href="#" id="top">Top</a>

<div id="container">
    
  
  <div id="sidebar">
    <h1>Index</h1>
    <ul id="index">

    <li class="set"><h3><a href="#header-functions">Functions</a></h3>
      
  <ul>
    <li class="mono"><a href="#noxer.nn.test_dnn_v_dnn">test_dnn_v_dnn</a></li>
    <li class="mono"><a href="#noxer.nn.test_rnn">test_rnn</a></li>
  </ul>

    </li>

    <li class="set"><h3><a href="#header-classes">Classes</a></h3>
      <ul>
        <li class="mono">
        <span class="class_name"><a href="#noxer.nn.CNN1DClassificationNN">CNN1DClassificationNN</a></span>
        
          
  <ul>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.__init__">__init__</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.add_module">add_module</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.apply">apply</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.children">children</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.cpu">cpu</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.cuda">cuda</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.double">double</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.eval">eval</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.float">float</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.forward">forward</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.half">half</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.load_state_dict">load_state_dict</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.modules">modules</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.named_children">named_children</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.named_modules">named_modules</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.named_parameters">named_parameters</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.parameters">parameters</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.register_backward_hook">register_backward_hook</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.register_buffer">register_buffer</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.register_forward_hook">register_forward_hook</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.register_forward_pre_hook">register_forward_pre_hook</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.register_parameter">register_parameter</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.share_memory">share_memory</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.state_dict">state_dict</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.train">train</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.type">type</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassificationNN.zero_grad">zero_grad</a></li>
  </ul>

        </li>
        <li class="mono">
        <span class="class_name"><a href="#noxer.nn.CNN1DClassifier">CNN1DClassifier</a></span>
        
          
  <ul>
    <li class="mono"><a href="#noxer.nn.CNN1DClassifier.__init__">__init__</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassifier.fit">fit</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassifier.get_params">get_params</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassifier.make_architecture">make_architecture</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassifier.predict">predict</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassifier.score">score</a></li>
    <li class="mono"><a href="#noxer.nn.CNN1DClassifier.set_params">set_params</a></li>
  </ul>

        </li>
        <li class="mono">
        <span class="class_name"><a href="#noxer.nn.FFNNClassificationNN">FFNNClassificationNN</a></span>
        
          
  <ul>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.__init__">__init__</a></li>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.add_module">add_module</a></li>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.apply">apply</a></li>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.children">children</a></li>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.cpu">cpu</a></li>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.cuda">cuda</a></li>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.double">double</a></li>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.eval">eval</a></li>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.float">float</a></li>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.forward">forward</a></li>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.half">half</a></li>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.load_state_dict">load_state_dict</a></li>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.modules">modules</a></li>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.named_children">named_children</a></li>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.named_modules">named_modules</a></li>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.named_parameters">named_parameters</a></li>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.parameters">parameters</a></li>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.register_backward_hook">register_backward_hook</a></li>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.register_buffer">register_buffer</a></li>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.register_forward_hook">register_forward_hook</a></li>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.register_forward_pre_hook">register_forward_pre_hook</a></li>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.register_parameter">register_parameter</a></li>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.share_memory">share_memory</a></li>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.state_dict">state_dict</a></li>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.train">train</a></li>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.type">type</a></li>
    <li class="mono"><a href="#noxer.nn.FFNNClassificationNN.zero_grad">zero_grad</a></li>
  </ul>

        </li>
        <li class="mono">
        <span class="class_name"><a href="#noxer.nn.GRUClassification">GRUClassification</a></span>
        
          
  <ul>
    <li class="mono"><a href="#noxer.nn.GRUClassification.__init__">__init__</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassification.add_module">add_module</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassification.apply">apply</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassification.children">children</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassification.cpu">cpu</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassification.cuda">cuda</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassification.double">double</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassification.eval">eval</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassification.float">float</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassification.forward">forward</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassification.half">half</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassification.load_state_dict">load_state_dict</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassification.modules">modules</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassification.named_children">named_children</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassification.named_modules">named_modules</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassification.named_parameters">named_parameters</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassification.parameters">parameters</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassification.register_backward_hook">register_backward_hook</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassification.register_buffer">register_buffer</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassification.register_forward_hook">register_forward_hook</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassification.register_forward_pre_hook">register_forward_pre_hook</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassification.register_parameter">register_parameter</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassification.share_memory">share_memory</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassification.state_dict">state_dict</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassification.train">train</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassification.type">type</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassification.zero_grad">zero_grad</a></li>
  </ul>

        </li>
        <li class="mono">
        <span class="class_name"><a href="#noxer.nn.GRUClassifier">GRUClassifier</a></span>
        
          
  <ul>
    <li class="mono"><a href="#noxer.nn.GRUClassifier.__init__">__init__</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassifier.fit">fit</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassifier.get_params">get_params</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassifier.make_architecture">make_architecture</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassifier.predict">predict</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassifier.score">score</a></li>
    <li class="mono"><a href="#noxer.nn.GRUClassifier.set_params">set_params</a></li>
  </ul>

        </li>
        <li class="mono">
        <span class="class_name"><a href="#noxer.nn.MLPClassifier">MLPClassifier</a></span>
        
          
  <ul>
    <li class="mono"><a href="#noxer.nn.MLPClassifier.__init__">__init__</a></li>
    <li class="mono"><a href="#noxer.nn.MLPClassifier.fit">fit</a></li>
    <li class="mono"><a href="#noxer.nn.MLPClassifier.get_params">get_params</a></li>
    <li class="mono"><a href="#noxer.nn.MLPClassifier.make_architecture">make_architecture</a></li>
    <li class="mono"><a href="#noxer.nn.MLPClassifier.predict">predict</a></li>
    <li class="mono"><a href="#noxer.nn.MLPClassifier.score">score</a></li>
    <li class="mono"><a href="#noxer.nn.MLPClassifier.set_params">set_params</a></li>
  </ul>

        </li>
        <li class="mono">
        <span class="class_name"><a href="#noxer.nn.PTLBase">PTLBase</a></span>
        
          
  <ul>
    <li class="mono"><a href="#noxer.nn.PTLBase.__init__">__init__</a></li>
    <li class="mono"><a href="#noxer.nn.PTLBase.fit">fit</a></li>
    <li class="mono"><a href="#noxer.nn.PTLBase.get_params">get_params</a></li>
    <li class="mono"><a href="#noxer.nn.PTLBase.make_architecture">make_architecture</a></li>
    <li class="mono"><a href="#noxer.nn.PTLBase.predict">predict</a></li>
    <li class="mono"><a href="#noxer.nn.PTLBase.set_params">set_params</a></li>
  </ul>

        </li>
        <li class="mono">
        <span class="class_name"><a href="#noxer.nn.PTLClassifierBase">PTLClassifierBase</a></span>
        
          
  <ul>
    <li class="mono"><a href="#noxer.nn.PTLClassifierBase.__init__">__init__</a></li>
    <li class="mono"><a href="#noxer.nn.PTLClassifierBase.fit">fit</a></li>
    <li class="mono"><a href="#noxer.nn.PTLClassifierBase.get_params">get_params</a></li>
    <li class="mono"><a href="#noxer.nn.PTLClassifierBase.make_architecture">make_architecture</a></li>
    <li class="mono"><a href="#noxer.nn.PTLClassifierBase.predict">predict</a></li>
    <li class="mono"><a href="#noxer.nn.PTLClassifierBase.score">score</a></li>
    <li class="mono"><a href="#noxer.nn.PTLClassifierBase.set_params">set_params</a></li>
  </ul>

        </li>
      </ul>
    </li>

    </ul>
  </div>

    <article id="content">
      
  

  


  <header id="section-intro">
  <h1 class="title"><span class="name">noxer.nn</span> module</h1>
  
  
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn" class="source">
    <div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">abstractmethod</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">ClassifierMixin</span><span class="p">,</span> <span class="n">RegressorMixin</span><span class="p">,</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">check_X_y</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.utils.data</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="kn">as</span> <span class="nn">optim</span>


<span class="k">class</span> <span class="nc">PTLBase</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A base class for learning algorithms with pytorch.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    epochs: int &gt; 0</span>
<span class="sd">        Number of epochs to train neural network for.</span>

<span class="sd">    batch_size: int &gt; 0</span>
<span class="sd">        Size of subsample of dataset to use to approximate the gradient in</span>
<span class="sd">        stochatic gradient descent procedure.</span>

<span class="sd">    alpha: float &gt; 0</span>
<span class="sd">        Learning rate. Tunes the amount of update done after processing of</span>
<span class="sd">        single batch size.</span>

<span class="sd">    beta1: float 0.0 &lt; x &lt; 1.0</span>
<span class="sd">        Beta 1 parameter of Adam stochastic gradient descent algorithm.</span>

<span class="sd">    beta2: float 0.0 &lt; x &lt; 1.0</span>
<span class="sd">        Beta 2 parameter of Adam stochastic gradient descent algorithm.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="n">epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">=</span> <span class="n">beta1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span> <span class="o">=</span> <span class="n">beta2</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">make_architecture</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Should return nn.Module instance, which represents architecture</span>
<span class="sd">        of the neural network.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        X: iterable of size n_samples</span>
<span class="sd">            Representation of dataset.</span>

<span class="sd">        y: iterable of size n_samples</span>
<span class="sd">            Representation of output</span>

<span class="sd">        Return</span>
<span class="sd">        ------</span>
<span class="sd">        net: an instance of a neural network to be trained.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">criterion</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Trains a neural network on provided data.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        X: iterable of size n_samples</span>
<span class="sd">            Representation of dataset.</span>

<span class="sd">        y: iterable of size n_samples</span>
<span class="sd">            Representation of output</span>

<span class="sd">        criterion: callable with 2 arguments, possibly a nn._Loss instance.</span>
<span class="sd">            Cost function to minimize.</span>

<span class="sd">        Return</span>
<span class="sd">        ------</span>
<span class="sd">        self</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_X_y</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">allow_nd</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_architecture</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span><span class="p">))</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TensorDataset</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># this creates mixed batches</span>
        <span class="n">trainloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">epochs</span><span class="p">):</span>  <span class="c1"># loop over the dataset multiple times</span>

            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">trainloader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
                <span class="c1"># get the inputs</span>
                <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>

                <span class="c1"># wrap them in Variable</span>
                <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="n">Variable</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

                <span class="c1"># zero the parameter gradients</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

                <span class="c1"># forward + backward + optimize</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Make estimation with trained neural network.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        X: iterable of size n_samples</span>
<span class="sd">            Representation of inputs. Should be consistent with</span>
<span class="sd">            inputs in the training dataset.</span>

<span class="sd">        Return</span>
<span class="sd">        ------</span>
<span class="sd">        X: iterable of size n_samples</span>
<span class="sd">            Representation of estimated outputs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;The model is not fit. Did you forget to call the fit method on a dataset?&quot;</span><span class="p">)</span>

        <span class="n">X</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">volatile</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">yp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">yp</span>


<span class="k">class</span> <span class="nc">PTLClassifierBase</span><span class="p">(</span><span class="n">PTLBase</span><span class="p">,</span> <span class="n">ClassifierMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A base class for learning classifiers with pytorch.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    See parent classes for corresponding parameters.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
                 <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PTLClassifierBase</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Trains a classifier on provided data.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        X: iterable of size n_samples</span>
<span class="sd">            Representation of dataset.</span>

<span class="sd">        y: iterable of size n_samples</span>
<span class="sd">            Representation of classes</span>

<span class="sd">        Return</span>
<span class="sd">        ------</span>
<span class="sd">        self</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># encode outputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PTLClassifierBase</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Estimate output classes.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X: iterable of size n_samples</span>
<span class="sd">            Representation of inputs to classify.</span>

<span class="sd">        Return</span>
<span class="sd">        ------</span>
<span class="sd">        y: iterable of size n_samples</span>
<span class="sd">            Representation of classes</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">yp</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">PTLClassifierBase</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">yp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">yp</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">yp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">yp</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">yp</span>


<span class="k">class</span> <span class="nc">FFNNClassificationNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Simple fully connected feed forward NN.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    xsz: int &gt; 0</span>
<span class="sd">        Size of input vector</span>

<span class="sd">    ysz: int &gt; 0</span>
<span class="sd">        Size of output vector</span>

<span class="sd">    n_layers: int &gt; 0</span>
<span class="sd">        Number of layers in the neural network</span>

<span class="sd">    n_neurons: int &gt; 0</span>
<span class="sd">        Number of neurons in every layer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xsz</span><span class="p">,</span> <span class="n">ysz</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FFNNClassificationNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">hsz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">xsz</span><span class="p">)</span>
        <span class="n">ysz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">ysz</span><span class="p">)</span>
        <span class="n">n_neurons</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span>
        <span class="n">n_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">dropout</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>

        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">):</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hsz</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">())</span>
            <span class="k">if</span> <span class="n">dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">dropout</span> <span class="o">&gt;</span> <span class="mf">0.03</span><span class="p">:</span>
                    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">))</span>
            <span class="n">hsz</span> <span class="o">=</span> <span class="n">n_neurons</span>

        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hsz</span><span class="p">,</span> <span class="n">ysz</span><span class="p">))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">l</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>


<span class="k">class</span> <span class="nc">MLPClassifier</span><span class="p">(</span><span class="n">PTLClassifierBase</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Estimator with Feed Forward Neural Network.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    For any parameters not listed, see PTLClassifierBase.</span>

<span class="sd">    n_layers: int &gt; 0</span>
<span class="sd">        Number of layers in the NN</span>

<span class="sd">    n_neurons: int &gt; 0</span>
<span class="sd">        Number of neurons in every layer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
                 <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MLPClassifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span> <span class="o">=</span> <span class="n">n_neurons</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>

    <span class="k">def</span> <span class="nf">make_architecture</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        See PTLBase.make_architecture for explanations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">net</span> <span class="o">=</span> <span class="n">FFNNClassificationNN</span><span class="p">(</span>
            <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">y</span><span class="p">)),</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">net</span>


<span class="k">class</span> <span class="nc">CNN1DClassificationNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Simple fully connected feed forward NN.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    xsz: int &gt; 0</span>
<span class="sd">        Size of input vector</span>

<span class="sd">    ysz: int &gt; 0</span>
<span class="sd">        Size of output vector</span>

<span class="sd">    n_layers: int &gt; 0</span>
<span class="sd">        Number of layers in the neural network</span>

<span class="sd">    n_neurons: int &gt; 0</span>
<span class="sd">        Number of neurons in every layer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xsz</span><span class="p">,</span> <span class="n">ysz</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CNN1DClassificationNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">ssz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">xsz</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">hsz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">xsz</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">ysz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">ysz</span><span class="p">)</span>
        <span class="n">n_neurons</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span>
        <span class="n">n_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)</span>
        <span class="n">kernel_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">dropout</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>

        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">):</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">hsz</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">())</span>
            <span class="k">if</span> <span class="n">dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">dropout</span> <span class="o">&gt;</span> <span class="mf">0.03</span><span class="p">:</span>
                    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">))</span>
            <span class="n">hsz</span> <span class="o">=</span> <span class="n">n_neurons</span>
            <span class="c1"># here avoid empty sequence</span>
            <span class="n">essz</span> <span class="o">=</span> <span class="n">ssz</span> <span class="o">/</span> <span class="mf">2.0</span>
            <span class="k">if</span> <span class="n">essz</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
            <span class="n">ssz</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">essz</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">seq</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>

        <span class="c1"># calculate flatten</span>
        <span class="n">hsz</span> <span class="o">=</span> <span class="n">hsz</span> <span class="o">*</span> <span class="n">ssz</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">ffnn</span> <span class="o">=</span> <span class="n">FFNNClassificationNN</span><span class="p">(</span><span class="n">hsz</span><span class="p">,</span> <span class="n">ysz</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="n">n_neurons</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># reshape input to (batch size, channels, seq length)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">l</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># flatten the data</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffnn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="k">class</span> <span class="nc">CNN1DClassifier</span><span class="p">(</span><span class="n">PTLClassifierBase</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Estimator with one dimensional convolutional neural network.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    For any parameters not listed, see PTLClassifierBase.</span>

<span class="sd">    n_layers: int &gt; 0</span>
<span class="sd">        Number of layers in the NN</span>

<span class="sd">    n_neurons: int &gt; 0</span>
<span class="sd">        Number of neurons in every layer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
                 <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CNN1DClassifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span> <span class="o">=</span> <span class="n">n_neurons</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>

    <span class="k">def</span> <span class="nf">make_architecture</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        See PTLBase.make_architecture for explanations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">net</span> <span class="o">=</span> <span class="n">CNN1DClassificationNN</span><span class="p">(</span>
            <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">y</span><span class="p">)),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">net</span>


<span class="k">class</span> <span class="nc">GRUClassification</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Recurent neural network module. Maps sequence to vector output.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    xsz: int &gt; 0</span>
<span class="sd">        Size of input vector</span>

<span class="sd">    ysz: int &gt; 0</span>
<span class="sd">        Size of output vector</span>

<span class="sd">    n_layers: int &gt; 0</span>
<span class="sd">        Number of layers in the neural network</span>

<span class="sd">    n_neurons: int &gt; 0</span>
<span class="sd">        Number of neurons in every layer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xsz</span><span class="p">,</span> <span class="n">ysz</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GRUClassification</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">ssz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">xsz</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">hsz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">xsz</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">ysz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">ysz</span><span class="p">)</span>
        <span class="n">n_neurons</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span>
        <span class="n">n_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">dropout</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">hsz</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="c1"># calculate flatten</span>
        <span class="n">hsz</span> <span class="o">=</span> <span class="n">n_neurons</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">ffnn</span> <span class="o">=</span> <span class="n">FFNNClassificationNN</span><span class="p">(</span><span class="n">hsz</span><span class="p">,</span> <span class="n">ysz</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="n">n_neurons</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># swap to (seq_len, batch, input_size)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># flatten the data</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffnn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="k">class</span> <span class="nc">GRUClassifier</span><span class="p">(</span><span class="n">PTLClassifierBase</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Estimator with one dimensional convolutional neural network.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    For any parameters not listed, see PTLClassifierBase.</span>

<span class="sd">    n_layers: int &gt; 0</span>
<span class="sd">        Number of layers in the NN</span>

<span class="sd">    n_neurons: int &gt; 0</span>
<span class="sd">        Number of neurons in every layer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
                 <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GRUClassifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span> <span class="o">=</span> <span class="n">n_neurons</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>

    <span class="k">def</span> <span class="nf">make_architecture</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        See PTLBase.make_architecture for explanations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">net</span> <span class="o">=</span> <span class="n">GRUClassification</span><span class="p">(</span>
            <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">y</span><span class="p">)),</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">net</span>


<span class="k">def</span> <span class="nf">test_dnn_v_dnn</span><span class="p">(</span><span class="n">datafnc</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>
    <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
    <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
    <span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
    <span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
    <span class="kn">from</span> <span class="nn">searchgrid</span> <span class="kn">import</span> <span class="n">set_grid</span><span class="p">,</span> <span class="n">build_param_grid</span>

    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datafnc</span><span class="p">()</span>

    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="n">estimator</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
            <span class="n">StandardScaler</span><span class="p">(),</span>
            <span class="n">set_grid</span><span class="p">(</span>
                <span class="n">PMLPClassifier</span><span class="p">(),</span>
                <span class="n">epochs</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span> <span class="o">**</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">)],</span>
                <span class="n">n_layers</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)),</span>
                <span class="n">n_neurons</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span> <span class="o">**</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">)],</span>
                <span class="n">alpha</span><span class="o">=</span><span class="p">[</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
        <span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span>
        <span class="n">param_grid</span><span class="o">=</span><span class="n">build_param_grid</span><span class="p">(</span><span class="n">estimator</span><span class="p">),</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span>
    <span class="p">)</span>

    <span class="n">mlp</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
        <span class="n">estimator</span><span class="o">=</span><span class="n">make_pipeline</span><span class="p">(</span>
            <span class="n">StandardScaler</span><span class="p">(),</span>
            <span class="n">MLPClassifier</span><span class="p">(),</span>
        <span class="p">),</span>
        <span class="n">param_grid</span><span class="o">=</span><span class="p">{</span>
            <span class="s1">&#39;mlpclassifier__max_iter&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span> <span class="o">**</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">)]</span>
        <span class="p">},</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">cv</span><span class="o">=</span><span class="mi">3</span>
    <span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">mlp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">datafnc</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="n">mlp</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>



<span class="k">def</span> <span class="nf">test_rnn</span><span class="p">(</span><span class="n">datafnc</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>
    <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
    <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
    <span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
    <span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
    <span class="kn">from</span> <span class="nn">searchgrid</span> <span class="kn">import</span> <span class="n">set_grid</span><span class="p">,</span> <span class="n">build_param_grid</span>
    <span class="kn">from</span> <span class="nn">noxer.sequences</span> <span class="kn">import</span> <span class="n">PadSubsequence</span>

    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datafnc</span><span class="p">()</span>

    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="n">estimator</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
            <span class="n">set_grid</span><span class="p">(</span>
                <span class="n">GRUClassifier</span><span class="p">(</span><span class="n">n_neurons</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">),</span>
                <span class="n">alpha</span><span class="o">=</span><span class="p">[</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="p">)</span>


    <span class="n">estimator</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
            <span class="n">set_grid</span><span class="p">(</span>
                <span class="n">CNN1DClassifier</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="mi">64</span><span class="p">),</span>
                <span class="n">alpha</span><span class="o">=</span><span class="p">[</span><span class="mf">0.01</span><span class="p">],</span>
                <span class="n">n_layers</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                <span class="n">n_neurons</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">],</span>
                <span class="n">dropout</span><span class="o">=</span><span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
        <span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span>
        <span class="n">param_grid</span><span class="o">=</span><span class="n">build_param_grid</span><span class="p">(</span><span class="n">estimator</span><span class="p">),</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">datafnc</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
    <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_digits</span>

    <span class="k">def</span> <span class="nf">rnd_data</span><span class="p">():</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2048</span><span class="p">,</span> <span class="mi">30</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.0</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

    <span class="k">def</span> <span class="nf">rnn_data</span><span class="p">():</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2500</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">60</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.0</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

    <span class="c1">#test_dnn_v_dnn(rnd_data)</span>
    <span class="c1">#test_dnn_v_dnn(lambda : load_digits(return_X_y=True))</span>
    <span class="n">test_rnn</span><span class="p">(</span><span class="n">rnn_data</span><span class="p">)</span>
</pre></div>

  </div>

  </header>

  <section id="section-items">

    <h2 class="section-title" id="header-functions">Functions</h2>
      
  <div class="item">
    <div class="name def" id="noxer.nn.test_dnn_v_dnn">
    <p>def <span class="ident">test_dnn_v_dnn</span>(</p><p>datafnc)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.test_dnn_v_dnn', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.test_dnn_v_dnn" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">test_dnn_v_dnn</span><span class="p">(</span><span class="n">datafnc</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>
    <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
    <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
    <span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
    <span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
    <span class="kn">from</span> <span class="nn">searchgrid</span> <span class="kn">import</span> <span class="n">set_grid</span><span class="p">,</span> <span class="n">build_param_grid</span>

    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datafnc</span><span class="p">()</span>

    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="n">estimator</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
            <span class="n">StandardScaler</span><span class="p">(),</span>
            <span class="n">set_grid</span><span class="p">(</span>
                <span class="n">PMLPClassifier</span><span class="p">(),</span>
                <span class="n">epochs</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span> <span class="o">**</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">)],</span>
                <span class="n">n_layers</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)),</span>
                <span class="n">n_neurons</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span> <span class="o">**</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">)],</span>
                <span class="n">alpha</span><span class="o">=</span><span class="p">[</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
        <span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span>
        <span class="n">param_grid</span><span class="o">=</span><span class="n">build_param_grid</span><span class="p">(</span><span class="n">estimator</span><span class="p">),</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span>
    <span class="p">)</span>

    <span class="n">mlp</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
        <span class="n">estimator</span><span class="o">=</span><span class="n">make_pipeline</span><span class="p">(</span>
            <span class="n">StandardScaler</span><span class="p">(),</span>
            <span class="n">MLPClassifier</span><span class="p">(),</span>
        <span class="p">),</span>
        <span class="n">param_grid</span><span class="o">=</span><span class="p">{</span>
            <span class="s1">&#39;mlpclassifier__max_iter&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span> <span class="o">**</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">)]</span>
        <span class="p">},</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">cv</span><span class="o">=</span><span class="mi">3</span>
    <span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">mlp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">datafnc</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="n">mlp</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="noxer.nn.test_rnn">
    <p>def <span class="ident">test_rnn</span>(</p><p>datafnc)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.test_rnn', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.test_rnn" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">test_rnn</span><span class="p">(</span><span class="n">datafnc</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>
    <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
    <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
    <span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
    <span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
    <span class="kn">from</span> <span class="nn">searchgrid</span> <span class="kn">import</span> <span class="n">set_grid</span><span class="p">,</span> <span class="n">build_param_grid</span>
    <span class="kn">from</span> <span class="nn">noxer.sequences</span> <span class="kn">import</span> <span class="n">PadSubsequence</span>

    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datafnc</span><span class="p">()</span>

    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="n">estimator</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
            <span class="n">set_grid</span><span class="p">(</span>
                <span class="n">GRUClassifier</span><span class="p">(</span><span class="n">n_neurons</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">),</span>
                <span class="n">alpha</span><span class="o">=</span><span class="p">[</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="p">)</span>


    <span class="n">estimator</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
            <span class="n">set_grid</span><span class="p">(</span>
                <span class="n">CNN1DClassifier</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="mi">64</span><span class="p">),</span>
                <span class="n">alpha</span><span class="o">=</span><span class="p">[</span><span class="mf">0.01</span><span class="p">],</span>
                <span class="n">n_layers</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                <span class="n">n_neurons</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">],</span>
                <span class="n">dropout</span><span class="o">=</span><span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
        <span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span>
        <span class="n">param_grid</span><span class="o">=</span><span class="n">build_param_grid</span><span class="p">(</span><span class="n">estimator</span><span class="p">),</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">datafnc</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>

  </div>
</div>

  </div>
  

    <h2 class="section-title" id="header-classes">Classes</h2>
      
      <div class="item">
      <p id="noxer.nn.CNN1DClassificationNN" class="name">class <span class="ident">CNN1DClassificationNN</span></p>
      
  
    <div class="desc"><p>Simple fully connected feed forward NN.</p>
<h2>Parameters</h2>
<p>xsz: int &gt; 0
    Size of input vector</p>
<p>ysz: int &gt; 0
    Size of output vector</p>
<p>n_layers: int &gt; 0
    Number of layers in the neural network</p>
<p>n_neurons: int &gt; 0
    Number of neurons in every layer</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN" class="source">
    <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">CNN1DClassificationNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Simple fully connected feed forward NN.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    xsz: int &gt; 0</span>
<span class="sd">        Size of input vector</span>

<span class="sd">    ysz: int &gt; 0</span>
<span class="sd">        Size of output vector</span>

<span class="sd">    n_layers: int &gt; 0</span>
<span class="sd">        Number of layers in the neural network</span>

<span class="sd">    n_neurons: int &gt; 0</span>
<span class="sd">        Number of neurons in every layer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xsz</span><span class="p">,</span> <span class="n">ysz</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CNN1DClassificationNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">ssz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">xsz</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">hsz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">xsz</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">ysz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">ysz</span><span class="p">)</span>
        <span class="n">n_neurons</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span>
        <span class="n">n_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)</span>
        <span class="n">kernel_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">dropout</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>

        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">):</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">hsz</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">())</span>
            <span class="k">if</span> <span class="n">dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">dropout</span> <span class="o">&gt;</span> <span class="mf">0.03</span><span class="p">:</span>
                    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">))</span>
            <span class="n">hsz</span> <span class="o">=</span> <span class="n">n_neurons</span>
            <span class="c1"># here avoid empty sequence</span>
            <span class="n">essz</span> <span class="o">=</span> <span class="n">ssz</span> <span class="o">/</span> <span class="mf">2.0</span>
            <span class="k">if</span> <span class="n">essz</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
            <span class="n">ssz</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">essz</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">seq</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>

        <span class="c1"># calculate flatten</span>
        <span class="n">hsz</span> <span class="o">=</span> <span class="n">hsz</span> <span class="o">*</span> <span class="n">ssz</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">ffnn</span> <span class="o">=</span> <span class="n">FFNNClassificationNN</span><span class="p">(</span><span class="n">hsz</span><span class="p">,</span> <span class="n">ysz</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="n">n_neurons</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># reshape input to (batch size, channels, seq length)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">l</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># flatten the data</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffnn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>

  </div>
</div>


      <div class="class">
          <h3>Ancestors (in MRO)</h3>
          <ul class="class_list">
          <li><a href="#noxer.nn.CNN1DClassificationNN">CNN1DClassificationNN</a></li>
          <li>torch.nn.modules.module.Module</li>
          <li>builtins.object</li>
          </ul>
          <h3>Class variables</h3>
            <div class="item">
            <p id="noxer.nn.CNN1DClassificationNN.dump_patches" class="name">var <span class="ident">dump_patches</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
          <h3>Static methods</h3>
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.__init__">
    <p>def <span class="ident">__init__</span>(</p><p>self, xsz, ysz, n_neurons=64, n_layers=1, kernel_size=3, dropout=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Initialize self.  See help(type(self)) for accurate signature.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.__init__', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.__init__" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xsz</span><span class="p">,</span> <span class="n">ysz</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">CNN1DClassificationNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="n">ssz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">xsz</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">hsz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">xsz</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">ysz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">ysz</span><span class="p">)</span>
    <span class="n">n_neurons</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span>
    <span class="n">n_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)</span>
    <span class="n">kernel_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">dropout</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">):</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">hsz</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">dropout</span> <span class="o">&gt;</span> <span class="mf">0.03</span><span class="p">:</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">))</span>
        <span class="n">hsz</span> <span class="o">=</span> <span class="n">n_neurons</span>
        <span class="c1"># here avoid empty sequence</span>
        <span class="n">essz</span> <span class="o">=</span> <span class="n">ssz</span> <span class="o">/</span> <span class="mf">2.0</span>
        <span class="k">if</span> <span class="n">essz</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
        <span class="n">ssz</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">essz</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">seq</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>
    <span class="c1"># calculate flatten</span>
    <span class="n">hsz</span> <span class="o">=</span> <span class="n">hsz</span> <span class="o">*</span> <span class="n">ssz</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ffnn</span> <span class="o">=</span> <span class="n">FFNNClassificationNN</span><span class="p">(</span><span class="n">hsz</span><span class="p">,</span> <span class="n">ysz</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="n">n_neurons</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.add_module">
    <p>def <span class="ident">add_module</span>(</p><p>self, name, module)</p>
    </div>
    

    
  
    <div class="desc"><p>Adds a child module to the current module.</p>
<p>The module can be accessed as an attribute using the given name.</p>
<p>Args:
    name (string): name of the child module. The child module can be
        accessed from this module using the given name
    parameter (Module): child module to be added to the module.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.add_module', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.add_module" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">add_module</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Adds a child module to the current module.</span>
<span class="sd">    The module can be accessed as an attribute using the given name.</span>
<span class="sd">    Args:</span>
<span class="sd">        name (string): name of the child module. The child module can be</span>
<span class="sd">            accessed from this module using the given name</span>
<span class="sd">        parameter (Module): child module to be added to the module.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">Module</span><span class="p">)</span> <span class="ow">and</span> <span class="n">module</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;{} is not a Module subclass&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">typename</span><span class="p">(</span><span class="n">module</span><span class="p">)))</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;attribute &#39;{}&#39; already exists&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">module</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.apply">
    <p>def <span class="ident">apply</span>(</p><p>self, fn)</p>
    </div>
    

    
  
    <div class="desc"><p>Applies <code>fn</code> recursively to every submodule (as returned by <code>.children()</code>)
as well as self. Typical use includes initializing the parameters of a model
(see also :ref:<code>torch-nn-init</code>).</p>
<p>Args:
    fn (:class:<code>Module</code> -&gt; None): function to be applied to each submodule</p>
<p>Returns:
    Module: self</p>
<p>Example:
    &gt;&gt;&gt; def init_weights(m):
    &gt;&gt;&gt;     print(m)
    &gt;&gt;&gt;     if type(m) == nn.Linear:
    &gt;&gt;&gt;         m.weight.data.fill_(1.0)
    &gt;&gt;&gt;         print(m.weight)
    &gt;&gt;&gt;
    &gt;&gt;&gt; net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))
    &gt;&gt;&gt; net.apply(init_weights)
    Linear (2 -&gt; 2)
    Parameter containing:
     1  1
     1  1
    [torch.FloatTensor of size 2x2]
    Linear (2 -&gt; 2)
    Parameter containing:
     1  1
     1  1
    [torch.FloatTensor of size 2x2]
    Sequential (
      (0): Linear (2 -&gt; 2)
      (1): Linear (2 -&gt; 2)
    )</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.apply', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.apply" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Applies ``fn`` recursively to every submodule (as returned by ``.children()``)</span>
<span class="sd">    as well as self. Typical use includes initializing the parameters of a model</span>
<span class="sd">    (see also :ref:`torch-nn-init`).</span>
<span class="sd">    Args:</span>
<span class="sd">        fn (:class:`Module` -&gt; None): function to be applied to each submodule</span>
<span class="sd">    Returns:</span>
<span class="sd">        Module: self</span>
<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; def init_weights(m):</span>
<span class="sd">        &gt;&gt;&gt;     print(m)</span>
<span class="sd">        &gt;&gt;&gt;     if type(m) == nn.Linear:</span>
<span class="sd">        &gt;&gt;&gt;         m.weight.data.fill_(1.0)</span>
<span class="sd">        &gt;&gt;&gt;         print(m.weight)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))</span>
<span class="sd">        &gt;&gt;&gt; net.apply(init_weights)</span>
<span class="sd">        Linear (2 -&gt; 2)</span>
<span class="sd">        Parameter containing:</span>
<span class="sd">         1  1</span>
<span class="sd">         1  1</span>
<span class="sd">        [torch.FloatTensor of size 2x2]</span>
<span class="sd">        Linear (2 -&gt; 2)</span>
<span class="sd">        Parameter containing:</span>
<span class="sd">         1  1</span>
<span class="sd">         1  1</span>
<span class="sd">        [torch.FloatTensor of size 2x2]</span>
<span class="sd">        Sequential (</span>
<span class="sd">          (0): Linear (2 -&gt; 2)</span>
<span class="sd">          (1): Linear (2 -&gt; 2)</span>
<span class="sd">        )</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">():</span>
        <span class="n">module</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="n">fn</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.children">
    <p>def <span class="ident">children</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns an iterator over immediate children modules.</p>
<p>Yields:
    Module: a child module</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.children', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.children" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">children</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns an iterator over immediate children modules.</span>
<span class="sd">    Yields:</span>
<span class="sd">        Module: a child module</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
        <span class="k">yield</span> <span class="n">module</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.cpu">
    <p>def <span class="ident">cpu</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Moves all model parameters and buffers to the CPU.</p>
<p>Returns:
    Module: self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.cpu', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.cpu" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">cpu</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Moves all model parameters and buffers to the CPU.</span>
<span class="sd">    Returns:</span>
<span class="sd">        Module: self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.cuda">
    <p>def <span class="ident">cuda</span>(</p><p>self, device=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Moves all model parameters and buffers to the GPU.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on GPU while being optimized.</p>
<p>Arguments:
    device (int, optional): if specified, all parameters will be
        copied to that device</p>
<p>Returns:
    Module: self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.cuda', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.cuda" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">cuda</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Moves all model parameters and buffers to the GPU.</span>
<span class="sd">    This also makes associated parameters and buffers different objects. So</span>
<span class="sd">    it should be called before constructing optimizer if the module will</span>
<span class="sd">    live on GPU while being optimized.</span>
<span class="sd">    Arguments:</span>
<span class="sd">        device (int, optional): if specified, all parameters will be</span>
<span class="sd">            copied to that device</span>
<span class="sd">    Returns:</span>
<span class="sd">        Module: self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.double">
    <p>def <span class="ident">double</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Casts all parameters and buffers to double datatype.</p>
<p>Returns:
    Module: self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.double', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.double" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">double</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Casts all parameters and buffers to double datatype.</span>
<span class="sd">    Returns:</span>
<span class="sd">        Module: self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">double</span><span class="p">())</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.eval">
    <p>def <span class="ident">eval</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Sets the module in evaluation mode.</p>
<p>This has any effect only on modules such as Dropout or BatchNorm.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.eval', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.eval" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">eval</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets the module in evaluation mode.</span>
<span class="sd">    This has any effect only on modules such as Dropout or BatchNorm.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.float">
    <p>def <span class="ident">float</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Casts all parameters and buffers to float datatype.</p>
<p>Returns:
    Module: self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.float', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.float" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">float</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Casts all parameters and buffers to float datatype.</span>
<span class="sd">    Returns:</span>
<span class="sd">        Module: self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.forward">
    <p>def <span class="ident">forward</span>(</p><p>self, x)</p>
    </div>
    

    
  
    <div class="desc"><p>Defines the computation performed at every call.</p>
<p>Should be overriden by all subclasses.</p>
<p>.. note::
    Although the recipe for forward pass needs to be defined within
    this function, one should call the :class:<code>Module</code> instance afterwards
    instead of this since the former takes care of running the
    registered hooks while the latter silently ignores them.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.forward', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.forward" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="c1"># reshape input to (batch size, channels, seq length)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">l</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1"># flatten the data</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffnn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.half">
    <p>def <span class="ident">half</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Casts all parameters and buffers to half datatype.</p>
<p>Returns:
    Module: self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.half', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.half" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">half</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Casts all parameters and buffers to half datatype.</span>
<span class="sd">    Returns:</span>
<span class="sd">        Module: self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">half</span><span class="p">())</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.load_state_dict">
    <p>def <span class="ident">load_state_dict</span>(</p><p>self, state_dict, strict=True)</p>
    </div>
    

    
  
    <div class="desc"><p>Copies parameters and buffers from :attr:<code>state_dict</code> into
this module and its descendants. If :attr:<code>strict</code> is <code>True</code> then
the keys of :attr:<code>state_dict</code> must exactly match the keys returned
by this module's :func:<code>state_dict()</code> function.</p>
<p>Arguments:
    state_dict (dict): A dict containing parameters and
        persistent buffers.
    strict (bool): Strictly enforce that the keys in :attr:<code>state_dict</code>
        match the keys returned by this module's <code>:func:</code>state_dict()`
        function.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.load_state_dict', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.load_state_dict" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Copies parameters and buffers from :attr:`state_dict` into</span>
<span class="sd">    this module and its descendants. If :attr:`strict` is ``True`` then</span>
<span class="sd">    the keys of :attr:`state_dict` must exactly match the keys returned</span>
<span class="sd">    by this module&#39;s :func:`state_dict()` function.</span>
<span class="sd">    Arguments:</span>
<span class="sd">        state_dict (dict): A dict containing parameters and</span>
<span class="sd">            persistent buffers.</span>
<span class="sd">        strict (bool): Strictly enforce that the keys in :attr:`state_dict`</span>
<span class="sd">            match the keys returned by this module&#39;s `:func:`state_dict()`</span>
<span class="sd">            function.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">own_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">own_state</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">):</span>
                <span class="c1"># backwards compatibility for serialized parameters</span>
                <span class="n">param</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">own_state</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;While copying the parameter named {}, &#39;</span>
                                   <span class="s1">&#39;whose dimensions in the model are {} and &#39;</span>
                                   <span class="s1">&#39;whose dimensions in the checkpoint are {}.&#39;</span>
                                   <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">own_state</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">()))</span>
        <span class="k">elif</span> <span class="n">strict</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s1">&#39;unexpected key &quot;{}&quot; in state_dict&#39;</span>
                           <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">strict</span><span class="p">:</span>
        <span class="n">missing</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">own_state</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">state_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">missing</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s1">&#39;missing keys in state_dict: &quot;{}&quot;&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">missing</span><span class="p">))</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.modules">
    <p>def <span class="ident">modules</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns an iterator over all modules in the network.</p>
<p>Yields:
    Module: a module in the network</p>
<p>Note:
    Duplicate modules are returned only once. In the following
    example, <code>l</code> will be returned only once.</p>
<div class="codehilite"><pre><span></span>&gt;&gt;&gt; l = nn.Linear(2, 2)
&gt;&gt;&gt; net = nn.Sequential(l, l)
&gt;&gt;&gt; for idx, m in enumerate(net.modules()):
&gt;&gt;&gt;     print(idx, &#39;-&gt;&#39;, m)
0 -&gt; Sequential (
  (0): Linear (2 -&gt; 2)
  (1): Linear (2 -&gt; 2)
)
1 -&gt; Linear (2 -&gt; 2)
</pre></div></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.modules', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.modules" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">modules</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns an iterator over all modules in the network.</span>
<span class="sd">    Yields:</span>
<span class="sd">        Module: a module in the network</span>
<span class="sd">    Note:</span>
<span class="sd">        Duplicate modules are returned only once. In the following</span>
<span class="sd">        example, ``l`` will be returned only once.</span>
<span class="sd">        &gt;&gt;&gt; l = nn.Linear(2, 2)</span>
<span class="sd">        &gt;&gt;&gt; net = nn.Sequential(l, l)</span>
<span class="sd">        &gt;&gt;&gt; for idx, m in enumerate(net.modules()):</span>
<span class="sd">        &gt;&gt;&gt;     print(idx, &#39;-&gt;&#39;, m)</span>
<span class="sd">        0 -&gt; Sequential (</span>
<span class="sd">          (0): Linear (2 -&gt; 2)</span>
<span class="sd">          (1): Linear (2 -&gt; 2)</span>
<span class="sd">        )</span>
<span class="sd">        1 -&gt; Linear (2 -&gt; 2)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
        <span class="k">yield</span> <span class="n">module</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.named_children">
    <p>def <span class="ident">named_children</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns an iterator over immediate children modules, yielding both
the name of the module as well as the module itself.</p>
<p>Yields:
    (string, Module): Tuple containing a name and child module</p>
<p>Example:
    &gt;&gt;&gt; for name, module in model.named_children():
    &gt;&gt;&gt;     if name in ['conv4', 'conv5']:
    &gt;&gt;&gt;         print(module)</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.named_children', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.named_children" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">named_children</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns an iterator over immediate children modules, yielding both</span>
<span class="sd">    the name of the module as well as the module itself.</span>
<span class="sd">    Yields:</span>
<span class="sd">        (string, Module): Tuple containing a name and child module</span>
<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; for name, module in model.named_children():</span>
<span class="sd">        &gt;&gt;&gt;     if name in [&#39;conv4&#39;, &#39;conv5&#39;]:</span>
<span class="sd">        &gt;&gt;&gt;         print(module)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">memo</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">module</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">module</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">memo</span><span class="p">:</span>
            <span class="n">memo</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.named_modules">
    <p>def <span class="ident">named_modules</span>(</p><p>self, memo=None, prefix=&#39;&#39;)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns an iterator over all modules in the network, yielding
both the name of the module as well as the module itself.</p>
<p>Yields:
    (string, Module): Tuple of name and module</p>
<p>Note:
    Duplicate modules are returned only once. In the following
    example, <code>l</code> will be returned only once.</p>
<div class="codehilite"><pre><span></span>&gt;&gt;&gt; l = nn.Linear(2, 2)
&gt;&gt;&gt; net = nn.Sequential(l, l)
&gt;&gt;&gt; for idx, m in enumerate(net.named_modules()):
&gt;&gt;&gt;     print(idx, &#39;-&gt;&#39;, m)
0 -&gt; (&#39;&#39;, Sequential (
  (0): Linear (2 -&gt; 2)
  (1): Linear (2 -&gt; 2)
))
1 -&gt; (&#39;0&#39;, Linear (2 -&gt; 2))
</pre></div></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.named_modules', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.named_modules" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">named_modules</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">memo</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns an iterator over all modules in the network, yielding</span>
<span class="sd">    both the name of the module as well as the module itself.</span>
<span class="sd">    Yields:</span>
<span class="sd">        (string, Module): Tuple of name and module</span>
<span class="sd">    Note:</span>
<span class="sd">        Duplicate modules are returned only once. In the following</span>
<span class="sd">        example, ``l`` will be returned only once.</span>
<span class="sd">        &gt;&gt;&gt; l = nn.Linear(2, 2)</span>
<span class="sd">        &gt;&gt;&gt; net = nn.Sequential(l, l)</span>
<span class="sd">        &gt;&gt;&gt; for idx, m in enumerate(net.named_modules()):</span>
<span class="sd">        &gt;&gt;&gt;     print(idx, &#39;-&gt;&#39;, m)</span>
<span class="sd">        0 -&gt; (&#39;&#39;, Sequential (</span>
<span class="sd">          (0): Linear (2 -&gt; 2)</span>
<span class="sd">          (1): Linear (2 -&gt; 2)</span>
<span class="sd">        ))</span>
<span class="sd">        1 -&gt; (&#39;0&#39;, Linear (2 -&gt; 2))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">memo</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">memo</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">if</span> <span class="bp">self</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">memo</span><span class="p">:</span>
        <span class="n">memo</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">yield</span> <span class="n">prefix</span><span class="p">,</span> <span class="bp">self</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">module</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">submodule_prefix</span> <span class="o">=</span> <span class="n">prefix</span> <span class="o">+</span> <span class="p">(</span><span class="s1">&#39;.&#39;</span> <span class="k">if</span> <span class="n">prefix</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="n">name</span>
            <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">named_modules</span><span class="p">(</span><span class="n">memo</span><span class="p">,</span> <span class="n">submodule_prefix</span><span class="p">):</span>
                <span class="k">yield</span> <span class="n">m</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.named_parameters">
    <p>def <span class="ident">named_parameters</span>(</p><p>self, memo=None, prefix=&#39;&#39;)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns an iterator over module parameters, yielding both the
name of the parameter as well as the parameter itself</p>
<p>Yields:
    (string, Parameter): Tuple containing the name and parameter</p>
<p>Example:
    &gt;&gt;&gt; for name, param in self.named_parameters():
    &gt;&gt;&gt;    if name in ['bias']:
    &gt;&gt;&gt;        print(param.size())</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.named_parameters', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.named_parameters" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">named_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">memo</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns an iterator over module parameters, yielding both the</span>
<span class="sd">    name of the parameter as well as the parameter itself</span>
<span class="sd">    Yields:</span>
<span class="sd">        (string, Parameter): Tuple containing the name and parameter</span>
<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; for name, param in self.named_parameters():</span>
<span class="sd">        &gt;&gt;&gt;    if name in [&#39;bias&#39;]:</span>
<span class="sd">        &gt;&gt;&gt;        print(param.size())</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">memo</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">memo</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">p</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">p</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">memo</span><span class="p">:</span>
            <span class="n">memo</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">prefix</span> <span class="o">+</span> <span class="p">(</span><span class="s1">&#39;.&#39;</span> <span class="k">if</span> <span class="n">prefix</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span>
    <span class="k">for</span> <span class="n">mname</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
        <span class="n">submodule_prefix</span> <span class="o">=</span> <span class="n">prefix</span> <span class="o">+</span> <span class="p">(</span><span class="s1">&#39;.&#39;</span> <span class="k">if</span> <span class="n">prefix</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="n">mname</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">(</span><span class="n">memo</span><span class="p">,</span> <span class="n">submodule_prefix</span><span class="p">):</span>
            <span class="k">yield</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.parameters">
    <p>def <span class="ident">parameters</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns an iterator over module parameters.</p>
<p>This is typically passed to an optimizer.</p>
<p>Yields:
    Parameter: module parameter</p>
<p>Example:
    &gt;&gt;&gt; for param in model.parameters():
    &gt;&gt;&gt;     print(type(param.data), param.size())
    <class 'torch.FloatTensor'> (20L,)
    <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.parameters', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.parameters" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns an iterator over module parameters.</span>
<span class="sd">    This is typically passed to an optimizer.</span>
<span class="sd">    Yields:</span>
<span class="sd">        Parameter: module parameter</span>
<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; for param in model.parameters():</span>
<span class="sd">        &gt;&gt;&gt;     print(type(param.data), param.size())</span>
<span class="sd">        &lt;class &#39;torch.FloatTensor&#39;&gt; (20L,)</span>
<span class="sd">        &lt;class &#39;torch.FloatTensor&#39;&gt; (20L, 1L, 5L, 5L)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
        <span class="k">yield</span> <span class="n">param</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.register_backward_hook">
    <p>def <span class="ident">register_backward_hook</span>(</p><p>self, hook)</p>
    </div>
    

    
  
    <div class="desc"><p>Registers a backward hook on the module.</p>
<p>The hook will be called every time the gradients with respect to module
inputs are computed. The hook should have the following signature::</p>
<div class="codehilite"><pre><span></span>hook(module, grad_input, grad_output) -&gt; Tensor or None
</pre></div>


<p>The :attr:<code>grad_input</code> and :attr:<code>grad_output</code> may be tuples if the
module has multiple inputs or outputs. The hook should not modify its
arguments, but it can optionally return a new gradient with respect to
input that will be used in place of :attr:<code>grad_input</code> in subsequent
computations.</p>
<p>Returns:
    :class:<code>torch.utils.hooks.RemovableHandle</code>:
        a handle that can be used to remove the added hook by calling
        <code>handle.remove()</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.register_backward_hook', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.register_backward_hook" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">register_backward_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hook</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Registers a backward hook on the module.</span>
<span class="sd">    The hook will be called every time the gradients with respect to module</span>
<span class="sd">    inputs are computed. The hook should have the following signature::</span>
<span class="sd">        hook(module, grad_input, grad_output) -&gt; Tensor or None</span>
<span class="sd">    The :attr:`grad_input` and :attr:`grad_output` may be tuples if the</span>
<span class="sd">    module has multiple inputs or outputs. The hook should not modify its</span>
<span class="sd">    arguments, but it can optionally return a new gradient with respect to</span>
<span class="sd">    input that will be used in place of :attr:`grad_input` in subsequent</span>
<span class="sd">    computations.</span>
<span class="sd">    Returns:</span>
<span class="sd">        :class:`torch.utils.hooks.RemovableHandle`:</span>
<span class="sd">            a handle that can be used to remove the added hook by calling</span>
<span class="sd">            ``handle.remove()``</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">handle</span> <span class="o">=</span> <span class="n">hooks</span><span class="o">.</span><span class="n">RemovableHandle</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span><span class="p">[</span><span class="n">handle</span><span class="o">.</span><span class="n">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">hook</span>
    <span class="k">return</span> <span class="n">handle</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.register_buffer">
    <p>def <span class="ident">register_buffer</span>(</p><p>self, name, tensor)</p>
    </div>
    

    
  
    <div class="desc"><p>Adds a persistent buffer to the module.</p>
<p>This is typically used to register a buffer that should not to be
considered a model parameter. For example, BatchNorm's <code>running_mean</code>
is not a parameter, but is part of the persistent state.</p>
<p>Buffers can be accessed as attributes using given names.</p>
<p>Args:
    name (string): name of the buffer. The buffer can be accessed
        from this module using the given name
    tensor (Tensor): buffer to be registered.</p>
<p>Example:
    &gt;&gt;&gt; self.register_buffer('running_mean', torch.zeros(num_features))</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.register_buffer', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.register_buffer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">register_buffer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Adds a persistent buffer to the module.</span>
<span class="sd">    This is typically used to register a buffer that should not to be</span>
<span class="sd">    considered a model parameter. For example, BatchNorm&#39;s ``running_mean``</span>
<span class="sd">    is not a parameter, but is part of the persistent state.</span>
<span class="sd">    Buffers can be accessed as attributes using given names.</span>
<span class="sd">    Args:</span>
<span class="sd">        name (string): name of the buffer. The buffer can be accessed</span>
<span class="sd">            from this module using the given name</span>
<span class="sd">        tensor (Tensor): buffer to be registered.</span>
<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; self.register_buffer(&#39;running_mean&#39;, torch.zeros(num_features))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_buffers</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;attribute &#39;{}&#39; already exists&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_buffers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">tensor</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.register_forward_hook">
    <p>def <span class="ident">register_forward_hook</span>(</p><p>self, hook)</p>
    </div>
    

    
  
    <div class="desc"><p>Registers a forward hook on the module.</p>
<p>The hook will be called every time after :func:<code>forward</code> has computed an output.
It should have the following signature::</p>
<div class="codehilite"><pre><span></span>hook(module, input, output) -&gt; None
</pre></div>


<p>The hook should not modify the input or output.</p>
<p>Returns:
    :class:<code>torch.utils.hooks.RemovableHandle</code>:
        a handle that can be used to remove the added hook by calling
        <code>handle.remove()</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.register_forward_hook', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.register_forward_hook" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">register_forward_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hook</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Registers a forward hook on the module.</span>
<span class="sd">    The hook will be called every time after :func:`forward` has computed an output.</span>
<span class="sd">    It should have the following signature::</span>
<span class="sd">        hook(module, input, output) -&gt; None</span>
<span class="sd">    The hook should not modify the input or output.</span>
<span class="sd">    Returns:</span>
<span class="sd">        :class:`torch.utils.hooks.RemovableHandle`:</span>
<span class="sd">            a handle that can be used to remove the added hook by calling</span>
<span class="sd">            ``handle.remove()``</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">handle</span> <span class="o">=</span> <span class="n">hooks</span><span class="o">.</span><span class="n">RemovableHandle</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span><span class="p">[</span><span class="n">handle</span><span class="o">.</span><span class="n">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">hook</span>
    <span class="k">return</span> <span class="n">handle</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.register_forward_pre_hook">
    <p>def <span class="ident">register_forward_pre_hook</span>(</p><p>self, hook)</p>
    </div>
    

    
  
    <div class="desc"><p>Registers a forward pre-hook on the module.</p>
<p>The hook will be called every time before :func:<code>forward</code> is invoked.
It should have the following signature::</p>
<div class="codehilite"><pre><span></span>hook(module, input) -&gt; None
</pre></div>


<p>The hook should not modify the input.</p>
<p>Returns:
    :class:<code>torch.utils.hooks.RemovableHandle</code>:
        a handle that can be used to remove the added hook by calling
        <code>handle.remove()</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.register_forward_pre_hook', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.register_forward_pre_hook" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">register_forward_pre_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hook</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Registers a forward pre-hook on the module.</span>
<span class="sd">    The hook will be called every time before :func:`forward` is invoked.</span>
<span class="sd">    It should have the following signature::</span>
<span class="sd">        hook(module, input) -&gt; None</span>
<span class="sd">    The hook should not modify the input.</span>
<span class="sd">    Returns:</span>
<span class="sd">        :class:`torch.utils.hooks.RemovableHandle`:</span>
<span class="sd">            a handle that can be used to remove the added hook by calling</span>
<span class="sd">            ``handle.remove()``</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">handle</span> <span class="o">=</span> <span class="n">hooks</span><span class="o">.</span><span class="n">RemovableHandle</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span><span class="p">[</span><span class="n">handle</span><span class="o">.</span><span class="n">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">hook</span>
    <span class="k">return</span> <span class="n">handle</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.register_parameter">
    <p>def <span class="ident">register_parameter</span>(</p><p>self, name, param)</p>
    </div>
    

    
  
    <div class="desc"><p>Adds a parameter to the module.</p>
<p>The parameter can be accessed as an attribute using given name.</p>
<p>Args:
    name (string): name of the parameter. The parameter can be accessed
        from this module using the given name
    parameter (Parameter): parameter to be added to the module.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.register_parameter', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.register_parameter" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">register_parameter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Adds a parameter to the module.</span>
<span class="sd">    The parameter can be accessed as an attribute using given name.</span>
<span class="sd">    Args:</span>
<span class="sd">        name (string): name of the parameter. The parameter can be accessed</span>
<span class="sd">            from this module using the given name</span>
<span class="sd">        parameter (Parameter): parameter to be added to the module.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="s1">&#39;_parameters&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
            <span class="s2">&quot;cannot assign parameter before Module.__init__() call&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;attribute &#39;{}&#39; already exists&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">param</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;cannot assign &#39;{}&#39; object to parameter &#39;{}&#39; &quot;</span>
                        <span class="s2">&quot;(torch.nn.Parameter or None required)&quot;</span>
                        <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">typename</span><span class="p">(</span><span class="n">param</span><span class="p">),</span> <span class="n">name</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">param</span><span class="o">.</span><span class="n">grad_fn</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Cannot assign non-leaf Variable to parameter &#39;{0}&#39;. Model &quot;</span>
            <span class="s2">&quot;parameters must be created explicitly. To express &#39;{0}&#39; &quot;</span>
            <span class="s2">&quot;as a function of another variable, compute the value in &quot;</span>
            <span class="s2">&quot;the forward() method.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.share_memory">
    <p>def <span class="ident">share_memory</span>(</p><p>self)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.share_memory', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.share_memory" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">share_memory</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">share_memory_</span><span class="p">())</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.state_dict">
    <p>def <span class="ident">state_dict</span>(</p><p>self, destination=None, prefix=&#39;&#39;, keep_vars=False)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns a dictionary containing a whole state of the module.</p>
<p>Both parameters and persistent buffers (e.g. running averages) are
included. Keys are corresponding parameter and buffer names.</p>
<p>When keep_vars is <code>True</code>, it returns a Variable for each parameter
(rather than a Tensor).</p>
<p>Args:
    destination (dict, optional):
        if not None, the return dictionary is stored into destination.
        Default: None
    prefix (string, optional): Adds a prefix to the key (name) of every
        parameter and buffer in the result dictionary. Default: ''
    keep_vars (bool, optional): if <code>True</code>, returns a Variable for each
        parameter. If <code>False</code>, returns a Tensor for each parameter.
        Default: <code>False</code></p>
<p>Returns:
    dict:
        a dictionary containing a whole state of the module</p>
<p>Example:
    &gt;&gt;&gt; module.state_dict().keys()
    ['bias', 'weight']</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.state_dict', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.state_dict" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">destination</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">keep_vars</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a dictionary containing a whole state of the module.</span>
<span class="sd">    Both parameters and persistent buffers (e.g. running averages) are</span>
<span class="sd">    included. Keys are corresponding parameter and buffer names.</span>
<span class="sd">    When keep_vars is ``True``, it returns a Variable for each parameter</span>
<span class="sd">    (rather than a Tensor).</span>
<span class="sd">    Args:</span>
<span class="sd">        destination (dict, optional):</span>
<span class="sd">            if not None, the return dictionary is stored into destination.</span>
<span class="sd">            Default: None</span>
<span class="sd">        prefix (string, optional): Adds a prefix to the key (name) of every</span>
<span class="sd">            parameter and buffer in the result dictionary. Default: &#39;&#39;</span>
<span class="sd">        keep_vars (bool, optional): if ``True``, returns a Variable for each</span>
<span class="sd">            parameter. If ``False``, returns a Tensor for each parameter.</span>
<span class="sd">            Default: ``False``</span>
<span class="sd">    Returns:</span>
<span class="sd">        dict:</span>
<span class="sd">            a dictionary containing a whole state of the module</span>
<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; module.state_dict().keys()</span>
<span class="sd">        [&#39;bias&#39;, &#39;weight&#39;]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">destination</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">destination</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">param</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">destination</span><span class="p">[</span><span class="n">prefix</span> <span class="o">+</span> <span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span> <span class="k">if</span> <span class="n">keep_vars</span> <span class="k">else</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">buf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_buffers</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">buf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">destination</span><span class="p">[</span><span class="n">prefix</span> <span class="o">+</span> <span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">buf</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">module</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">module</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(</span><span class="n">destination</span><span class="p">,</span> <span class="n">prefix</span> <span class="o">+</span> <span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">keep_vars</span><span class="o">=</span><span class="n">keep_vars</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">destination</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.train">
    <p>def <span class="ident">train</span>(</p><p>self, mode=True)</p>
    </div>
    

    
  
    <div class="desc"><p>Sets the module in training mode.</p>
<p>This has any effect only on modules such as Dropout or BatchNorm.</p>
<p>Returns:
    Module: self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.train', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.train" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets the module in training mode.</span>
<span class="sd">    This has any effect only on modules such as Dropout or BatchNorm.</span>
<span class="sd">    Returns:</span>
<span class="sd">        Module: self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="o">=</span> <span class="n">mode</span>
    <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">():</span>
        <span class="n">module</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.type">
    <p>def <span class="ident">type</span>(</p><p>self, dst_type)</p>
    </div>
    

    
  
    <div class="desc"><p>Casts all parameters and buffers to dst_type.</p>
<p>Arguments:
    dst_type (type or string): the desired type</p>
<p>Returns:
    Module: self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.type', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.type" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">type</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dst_type</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Casts all parameters and buffers to dst_type.</span>
<span class="sd">    Arguments:</span>
<span class="sd">        dst_type (type or string): the desired type</span>
<span class="sd">    Returns:</span>
<span class="sd">        Module: self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">dst_type</span><span class="p">))</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassificationNN.zero_grad">
    <p>def <span class="ident">zero_grad</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Sets gradients of all model parameters to zero.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassificationNN.zero_grad', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassificationNN.zero_grad" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets gradients of all model parameters to zero.&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">volatile</span><span class="p">:</span>
                <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span>
                <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">new</span><span class="p">()</span><span class="o">.</span><span class="n">resize_as_</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">zero_</span><span class="p">())</span>
</pre></div>

  </div>
</div>

  </div>
  
          <h3>Instance variables</h3>
            <div class="item">
            <p id="noxer.nn.CNN1DClassificationNN.ffnn" class="name">var <span class="ident">ffnn</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="noxer.nn.CNN1DClassificationNN.seq" class="name">var <span class="ident">seq</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
      </div>
      </div>
      
      <div class="item">
      <p id="noxer.nn.CNN1DClassifier" class="name">class <span class="ident">CNN1DClassifier</span></p>
      
  
    <div class="desc"><p>Estimator with one dimensional convolutional neural network.</p>
<h2>Parameters</h2>
<p>For any parameters not listed, see PTLClassifierBase.</p>
<p>n_layers: int &gt; 0
    Number of layers in the NN</p>
<p>n_neurons: int &gt; 0
    Number of neurons in every layer</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassifier', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassifier" class="source">
    <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">CNN1DClassifier</span><span class="p">(</span><span class="n">PTLClassifierBase</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Estimator with one dimensional convolutional neural network.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    For any parameters not listed, see PTLClassifierBase.</span>

<span class="sd">    n_layers: int &gt; 0</span>
<span class="sd">        Number of layers in the NN</span>

<span class="sd">    n_neurons: int &gt; 0</span>
<span class="sd">        Number of neurons in every layer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
                 <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CNN1DClassifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span> <span class="o">=</span> <span class="n">n_neurons</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>

    <span class="k">def</span> <span class="nf">make_architecture</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        See PTLBase.make_architecture for explanations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">net</span> <span class="o">=</span> <span class="n">CNN1DClassificationNN</span><span class="p">(</span>
            <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">y</span><span class="p">)),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">net</span>
</pre></div>

  </div>
</div>


      <div class="class">
          <h3>Ancestors (in MRO)</h3>
          <ul class="class_list">
          <li><a href="#noxer.nn.CNN1DClassifier">CNN1DClassifier</a></li>
          <li><a href="#noxer.nn.PTLClassifierBase">PTLClassifierBase</a></li>
          <li><a href="#noxer.nn.PTLBase">PTLBase</a></li>
          <li>sklearn.base.BaseEstimator</li>
          <li>sklearn.base.ClassifierMixin</li>
          <li>builtins.object</li>
          </ul>
          <h3>Static methods</h3>
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassifier.__init__">
    <p>def <span class="ident">__init__</span>(</p><p>self, kernel_size=3, dropout=None, n_layers=1, n_neurons=32, epochs=10, batch_size=256, alpha=0.001, beta1=0.9, beta2=0.999)</p>
    </div>
    

    
  
    <div class="desc"><p>Initialize self.  See help(type(self)) for accurate signature.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassifier.__init__', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassifier.__init__" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
             <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">CNN1DClassifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span> <span class="o">=</span> <span class="n">n_neurons</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassifier.fit">
    <p>def <span class="ident">fit</span>(</p><p>self, X, y)</p>
    </div>
    

    
  
    <div class="desc"><p>Trains a classifier on provided data.</p>
<h2>Parameters</h2>
<p>X: iterable of size n_samples
    Representation of dataset.</p>
<p>y: iterable of size n_samples
    Representation of classes</p>
<h2>Return</h2>
<p>self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassifier.fit', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassifier.fit" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Trains a classifier on provided data.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X: iterable of size n_samples</span>
<span class="sd">        Representation of dataset.</span>
<span class="sd">    y: iterable of size n_samples</span>
<span class="sd">        Representation of classes</span>
<span class="sd">    Return</span>
<span class="sd">    ------</span>
<span class="sd">    self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># encode outputs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
    <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">PTLClassifierBase</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassifier.get_params">
    <p>def <span class="ident">get_params</span>(</p><p>self, deep=True)</p>
    </div>
    

    
  
    <div class="desc"><p>Get parameters for this estimator.</p>
<h2>Parameters</h2>
<p>deep : boolean, optional
    If True, will return the parameters for this estimator and
    contained subobjects that are estimators.</p>
<h2>Returns</h2>
<p>params : mapping of string to any
    Parameter names mapped to their values.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassifier.get_params', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassifier.get_params" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get parameters for this estimator.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    deep : boolean, optional</span>
<span class="sd">        If True, will return the parameters for this estimator and</span>
<span class="sd">        contained subobjects that are estimators.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    params : mapping of string to any</span>
<span class="sd">        Parameter names mapped to their values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">out</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_param_names</span><span class="p">():</span>
        <span class="c1"># We need deprecation warnings to always be on in order to</span>
        <span class="c1"># catch deprecated param values.</span>
        <span class="c1"># This is set in utils/__init__.py but it gets overwritten</span>
        <span class="c1"># when running under python3 somehow.</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;always&quot;</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">(</span><span class="n">record</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">w</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="ow">and</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">category</span> <span class="o">==</span> <span class="ne">DeprecationWarning</span><span class="p">:</span>
                <span class="c1"># if the parameter is deprecated, don&#39;t show it</span>
                <span class="k">continue</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">filters</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># XXX: should we rather test if instance of estimator?</span>
        <span class="k">if</span> <span class="n">deep</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s1">&#39;get_params&#39;</span><span class="p">):</span>
            <span class="n">deep_items</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="n">out</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="n">key</span> <span class="o">+</span> <span class="s1">&#39;__&#39;</span> <span class="o">+</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">deep_items</span><span class="p">)</span>
        <span class="n">out</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
    <span class="k">return</span> <span class="n">out</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassifier.make_architecture">
    <p>def <span class="ident">make_architecture</span>(</p><p>self, X, y)</p>
    </div>
    

    
  
    <div class="desc"><p>See PTLBase.make_architecture for explanations.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassifier.make_architecture', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassifier.make_architecture" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">make_architecture</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    See PTLBase.make_architecture for explanations.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">CNN1DClassificationNN</span><span class="p">(</span>
        <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">y</span><span class="p">)),</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span>
        <span class="n">dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">net</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassifier.predict">
    <p>def <span class="ident">predict</span>(</p><p>self, X)</p>
    </div>
    

    
  
    <div class="desc"><p>Estimate output classes.</p>
<h2>Parameters</h2>
<p>X: iterable of size n_samples
    Representation of inputs to classify.</p>
<h2>Return</h2>
<p>y: iterable of size n_samples
    Representation of classes</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassifier.predict', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassifier.predict" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Estimate output classes.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X: iterable of size n_samples</span>
<span class="sd">        Representation of inputs to classify.</span>
<span class="sd">    Return</span>
<span class="sd">    ------</span>
<span class="sd">    y: iterable of size n_samples</span>
<span class="sd">        Representation of classes</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">yp</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">PTLClassifierBase</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">yp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">yp</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">yp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">yp</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">yp</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassifier.score">
    <p>def <span class="ident">score</span>(</p><p>self, X, y, sample_weight=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h2>Parameters</h2>
<p>X : array-like, shape = (n_samples, n_features)
    Test samples.</p>
<p>y : array-like, shape = (n_samples) or (n_samples, n_outputs)
    True labels for X.</p>
<p>sample_weight : array-like, shape = [n_samples], optional
    Sample weights.</p>
<h2>Returns</h2>
<p>score : float
    Mean accuracy of self.predict(X) wrt. y.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassifier.score', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassifier.score" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the mean accuracy on the given test data and labels.</span>
<span class="sd">    In multi-label classification, this is the subset accuracy</span>
<span class="sd">    which is a harsh metric since you require for each sample that</span>
<span class="sd">    each label set be correctly predicted.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array-like, shape = (n_samples, n_features)</span>
<span class="sd">        Test samples.</span>
<span class="sd">    y : array-like, shape = (n_samples) or (n_samples, n_outputs)</span>
<span class="sd">        True labels for X.</span>
<span class="sd">    sample_weight : array-like, shape = [n_samples], optional</span>
<span class="sd">        Sample weights.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score : float</span>
<span class="sd">        Mean accuracy of self.predict(X) wrt. y.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
    <span class="k">return</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.CNN1DClassifier.set_params">
    <p>def <span class="ident">set_params</span>(</p><p>self, **params)</p>
    </div>
    

    
  
    <div class="desc"><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2>Returns</h2>
<p>self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.CNN1DClassifier.set_params', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.CNN1DClassifier.set_params" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Set the parameters of this estimator.</span>
<span class="sd">    The method works on simple estimators as well as on nested objects</span>
<span class="sd">    (such as pipelines). The latter have parameters of the form</span>
<span class="sd">    ``&lt;component&gt;__&lt;parameter&gt;`` so that it&#39;s possible to update each</span>
<span class="sd">    component of a nested object.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">params</span><span class="p">:</span>
        <span class="c1"># Simple optimization to gain speed (inspect is slow)</span>
        <span class="k">return</span> <span class="bp">self</span>
    <span class="n">valid_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_params</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">nested_params</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">dict</span><span class="p">)</span>  <span class="c1"># grouped by prefix</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">key</span><span class="p">,</span> <span class="n">delim</span><span class="p">,</span> <span class="n">sub_key</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">partition</span><span class="p">(</span><span class="s1">&#39;__&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_params</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Invalid parameter </span><span class="si">%s</span><span class="s1"> for estimator </span><span class="si">%s</span><span class="s1">. &#39;</span>
                             <span class="s1">&#39;Check the list of available parameters &#39;</span>
                             <span class="s1">&#39;with `estimator.get_params().keys()`.&#39;</span> <span class="o">%</span>
                             <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">delim</span><span class="p">:</span>
            <span class="n">nested_params</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">sub_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">sub_params</span> <span class="ow">in</span> <span class="n">nested_params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">valid_params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">sub_params</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>

  </div>
</div>

  </div>
  
          <h3>Instance variables</h3>
            <div class="item">
            <p id="noxer.nn.CNN1DClassifier.dropout" class="name">var <span class="ident">dropout</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="noxer.nn.CNN1DClassifier.kernel_size" class="name">var <span class="ident">kernel_size</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="noxer.nn.CNN1DClassifier.n_layers" class="name">var <span class="ident">n_layers</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="noxer.nn.CNN1DClassifier.n_neurons" class="name">var <span class="ident">n_neurons</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
      </div>
      </div>
      
      <div class="item">
      <p id="noxer.nn.FFNNClassificationNN" class="name">class <span class="ident">FFNNClassificationNN</span></p>
      
  
    <div class="desc"><p>Simple fully connected feed forward NN.</p>
<h2>Parameters</h2>
<p>xsz: int &gt; 0
    Size of input vector</p>
<p>ysz: int &gt; 0
    Size of output vector</p>
<p>n_layers: int &gt; 0
    Number of layers in the neural network</p>
<p>n_neurons: int &gt; 0
    Number of neurons in every layer</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN" class="source">
    <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">FFNNClassificationNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Simple fully connected feed forward NN.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    xsz: int &gt; 0</span>
<span class="sd">        Size of input vector</span>

<span class="sd">    ysz: int &gt; 0</span>
<span class="sd">        Size of output vector</span>

<span class="sd">    n_layers: int &gt; 0</span>
<span class="sd">        Number of layers in the neural network</span>

<span class="sd">    n_neurons: int &gt; 0</span>
<span class="sd">        Number of neurons in every layer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xsz</span><span class="p">,</span> <span class="n">ysz</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FFNNClassificationNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">hsz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">xsz</span><span class="p">)</span>
        <span class="n">ysz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">ysz</span><span class="p">)</span>
        <span class="n">n_neurons</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span>
        <span class="n">n_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">dropout</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>

        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">):</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hsz</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">())</span>
            <span class="k">if</span> <span class="n">dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">dropout</span> <span class="o">&gt;</span> <span class="mf">0.03</span><span class="p">:</span>
                    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">))</span>
            <span class="n">hsz</span> <span class="o">=</span> <span class="n">n_neurons</span>

        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hsz</span><span class="p">,</span> <span class="n">ysz</span><span class="p">))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">l</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>
</pre></div>

  </div>
</div>


      <div class="class">
          <h3>Ancestors (in MRO)</h3>
          <ul class="class_list">
          <li><a href="#noxer.nn.FFNNClassificationNN">FFNNClassificationNN</a></li>
          <li>torch.nn.modules.module.Module</li>
          <li>builtins.object</li>
          </ul>
          <h3>Class variables</h3>
            <div class="item">
            <p id="noxer.nn.FFNNClassificationNN.dump_patches" class="name">var <span class="ident">dump_patches</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
          <h3>Static methods</h3>
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.__init__">
    <p>def <span class="ident">__init__</span>(</p><p>self, xsz, ysz, n_neurons, n_layers, dropout=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Initialize self.  See help(type(self)) for accurate signature.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.__init__', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.__init__" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xsz</span><span class="p">,</span> <span class="n">ysz</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">FFNNClassificationNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="n">hsz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">xsz</span><span class="p">)</span>
    <span class="n">ysz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">ysz</span><span class="p">)</span>
    <span class="n">n_neurons</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span>
    <span class="n">n_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">dropout</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">):</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hsz</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">dropout</span> <span class="o">&gt;</span> <span class="mf">0.03</span><span class="p">:</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">))</span>
        <span class="n">hsz</span> <span class="o">=</span> <span class="n">n_neurons</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hsz</span><span class="p">,</span> <span class="n">ysz</span><span class="p">))</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.add_module">
    <p>def <span class="ident">add_module</span>(</p><p>self, name, module)</p>
    </div>
    

    
  
    <div class="desc"><p>Adds a child module to the current module.</p>
<p>The module can be accessed as an attribute using the given name.</p>
<p>Args:
    name (string): name of the child module. The child module can be
        accessed from this module using the given name
    parameter (Module): child module to be added to the module.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.add_module', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.add_module" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">add_module</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Adds a child module to the current module.</span>
<span class="sd">    The module can be accessed as an attribute using the given name.</span>
<span class="sd">    Args:</span>
<span class="sd">        name (string): name of the child module. The child module can be</span>
<span class="sd">            accessed from this module using the given name</span>
<span class="sd">        parameter (Module): child module to be added to the module.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">Module</span><span class="p">)</span> <span class="ow">and</span> <span class="n">module</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;{} is not a Module subclass&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">typename</span><span class="p">(</span><span class="n">module</span><span class="p">)))</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;attribute &#39;{}&#39; already exists&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">module</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.apply">
    <p>def <span class="ident">apply</span>(</p><p>self, fn)</p>
    </div>
    

    
  
    <div class="desc"><p>Applies <code>fn</code> recursively to every submodule (as returned by <code>.children()</code>)
as well as self. Typical use includes initializing the parameters of a model
(see also :ref:<code>torch-nn-init</code>).</p>
<p>Args:
    fn (:class:<code>Module</code> -&gt; None): function to be applied to each submodule</p>
<p>Returns:
    Module: self</p>
<p>Example:
    &gt;&gt;&gt; def init_weights(m):
    &gt;&gt;&gt;     print(m)
    &gt;&gt;&gt;     if type(m) == nn.Linear:
    &gt;&gt;&gt;         m.weight.data.fill_(1.0)
    &gt;&gt;&gt;         print(m.weight)
    &gt;&gt;&gt;
    &gt;&gt;&gt; net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))
    &gt;&gt;&gt; net.apply(init_weights)
    Linear (2 -&gt; 2)
    Parameter containing:
     1  1
     1  1
    [torch.FloatTensor of size 2x2]
    Linear (2 -&gt; 2)
    Parameter containing:
     1  1
     1  1
    [torch.FloatTensor of size 2x2]
    Sequential (
      (0): Linear (2 -&gt; 2)
      (1): Linear (2 -&gt; 2)
    )</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.apply', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.apply" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Applies ``fn`` recursively to every submodule (as returned by ``.children()``)</span>
<span class="sd">    as well as self. Typical use includes initializing the parameters of a model</span>
<span class="sd">    (see also :ref:`torch-nn-init`).</span>
<span class="sd">    Args:</span>
<span class="sd">        fn (:class:`Module` -&gt; None): function to be applied to each submodule</span>
<span class="sd">    Returns:</span>
<span class="sd">        Module: self</span>
<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; def init_weights(m):</span>
<span class="sd">        &gt;&gt;&gt;     print(m)</span>
<span class="sd">        &gt;&gt;&gt;     if type(m) == nn.Linear:</span>
<span class="sd">        &gt;&gt;&gt;         m.weight.data.fill_(1.0)</span>
<span class="sd">        &gt;&gt;&gt;         print(m.weight)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))</span>
<span class="sd">        &gt;&gt;&gt; net.apply(init_weights)</span>
<span class="sd">        Linear (2 -&gt; 2)</span>
<span class="sd">        Parameter containing:</span>
<span class="sd">         1  1</span>
<span class="sd">         1  1</span>
<span class="sd">        [torch.FloatTensor of size 2x2]</span>
<span class="sd">        Linear (2 -&gt; 2)</span>
<span class="sd">        Parameter containing:</span>
<span class="sd">         1  1</span>
<span class="sd">         1  1</span>
<span class="sd">        [torch.FloatTensor of size 2x2]</span>
<span class="sd">        Sequential (</span>
<span class="sd">          (0): Linear (2 -&gt; 2)</span>
<span class="sd">          (1): Linear (2 -&gt; 2)</span>
<span class="sd">        )</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">():</span>
        <span class="n">module</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="n">fn</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.children">
    <p>def <span class="ident">children</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns an iterator over immediate children modules.</p>
<p>Yields:
    Module: a child module</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.children', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.children" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">children</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns an iterator over immediate children modules.</span>
<span class="sd">    Yields:</span>
<span class="sd">        Module: a child module</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
        <span class="k">yield</span> <span class="n">module</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.cpu">
    <p>def <span class="ident">cpu</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Moves all model parameters and buffers to the CPU.</p>
<p>Returns:
    Module: self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.cpu', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.cpu" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">cpu</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Moves all model parameters and buffers to the CPU.</span>
<span class="sd">    Returns:</span>
<span class="sd">        Module: self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.cuda">
    <p>def <span class="ident">cuda</span>(</p><p>self, device=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Moves all model parameters and buffers to the GPU.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on GPU while being optimized.</p>
<p>Arguments:
    device (int, optional): if specified, all parameters will be
        copied to that device</p>
<p>Returns:
    Module: self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.cuda', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.cuda" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">cuda</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Moves all model parameters and buffers to the GPU.</span>
<span class="sd">    This also makes associated parameters and buffers different objects. So</span>
<span class="sd">    it should be called before constructing optimizer if the module will</span>
<span class="sd">    live on GPU while being optimized.</span>
<span class="sd">    Arguments:</span>
<span class="sd">        device (int, optional): if specified, all parameters will be</span>
<span class="sd">            copied to that device</span>
<span class="sd">    Returns:</span>
<span class="sd">        Module: self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.double">
    <p>def <span class="ident">double</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Casts all parameters and buffers to double datatype.</p>
<p>Returns:
    Module: self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.double', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.double" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">double</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Casts all parameters and buffers to double datatype.</span>
<span class="sd">    Returns:</span>
<span class="sd">        Module: self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">double</span><span class="p">())</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.eval">
    <p>def <span class="ident">eval</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Sets the module in evaluation mode.</p>
<p>This has any effect only on modules such as Dropout or BatchNorm.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.eval', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.eval" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">eval</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets the module in evaluation mode.</span>
<span class="sd">    This has any effect only on modules such as Dropout or BatchNorm.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.float">
    <p>def <span class="ident">float</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Casts all parameters and buffers to float datatype.</p>
<p>Returns:
    Module: self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.float', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.float" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">float</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Casts all parameters and buffers to float datatype.</span>
<span class="sd">    Returns:</span>
<span class="sd">        Module: self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.forward">
    <p>def <span class="ident">forward</span>(</p><p>self, x)</p>
    </div>
    

    
  
    <div class="desc"><p>Defines the computation performed at every call.</p>
<p>Should be overriden by all subclasses.</p>
<p>.. note::
    Although the recipe for forward pass needs to be defined within
    this function, one should call the :class:<code>Module</code> instance afterwards
    instead of this since the former takes care of running the
    registered hooks while the latter silently ignores them.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.forward', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.forward" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">l</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.half">
    <p>def <span class="ident">half</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Casts all parameters and buffers to half datatype.</p>
<p>Returns:
    Module: self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.half', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.half" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">half</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Casts all parameters and buffers to half datatype.</span>
<span class="sd">    Returns:</span>
<span class="sd">        Module: self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">half</span><span class="p">())</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.load_state_dict">
    <p>def <span class="ident">load_state_dict</span>(</p><p>self, state_dict, strict=True)</p>
    </div>
    

    
  
    <div class="desc"><p>Copies parameters and buffers from :attr:<code>state_dict</code> into
this module and its descendants. If :attr:<code>strict</code> is <code>True</code> then
the keys of :attr:<code>state_dict</code> must exactly match the keys returned
by this module's :func:<code>state_dict()</code> function.</p>
<p>Arguments:
    state_dict (dict): A dict containing parameters and
        persistent buffers.
    strict (bool): Strictly enforce that the keys in :attr:<code>state_dict</code>
        match the keys returned by this module's <code>:func:</code>state_dict()`
        function.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.load_state_dict', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.load_state_dict" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Copies parameters and buffers from :attr:`state_dict` into</span>
<span class="sd">    this module and its descendants. If :attr:`strict` is ``True`` then</span>
<span class="sd">    the keys of :attr:`state_dict` must exactly match the keys returned</span>
<span class="sd">    by this module&#39;s :func:`state_dict()` function.</span>
<span class="sd">    Arguments:</span>
<span class="sd">        state_dict (dict): A dict containing parameters and</span>
<span class="sd">            persistent buffers.</span>
<span class="sd">        strict (bool): Strictly enforce that the keys in :attr:`state_dict`</span>
<span class="sd">            match the keys returned by this module&#39;s `:func:`state_dict()`</span>
<span class="sd">            function.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">own_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">own_state</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">):</span>
                <span class="c1"># backwards compatibility for serialized parameters</span>
                <span class="n">param</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">own_state</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;While copying the parameter named {}, &#39;</span>
                                   <span class="s1">&#39;whose dimensions in the model are {} and &#39;</span>
                                   <span class="s1">&#39;whose dimensions in the checkpoint are {}.&#39;</span>
                                   <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">own_state</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">()))</span>
        <span class="k">elif</span> <span class="n">strict</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s1">&#39;unexpected key &quot;{}&quot; in state_dict&#39;</span>
                           <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">strict</span><span class="p">:</span>
        <span class="n">missing</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">own_state</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">state_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">missing</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s1">&#39;missing keys in state_dict: &quot;{}&quot;&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">missing</span><span class="p">))</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.modules">
    <p>def <span class="ident">modules</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns an iterator over all modules in the network.</p>
<p>Yields:
    Module: a module in the network</p>
<p>Note:
    Duplicate modules are returned only once. In the following
    example, <code>l</code> will be returned only once.</p>
<div class="codehilite"><pre><span></span>&gt;&gt;&gt; l = nn.Linear(2, 2)
&gt;&gt;&gt; net = nn.Sequential(l, l)
&gt;&gt;&gt; for idx, m in enumerate(net.modules()):
&gt;&gt;&gt;     print(idx, &#39;-&gt;&#39;, m)
0 -&gt; Sequential (
  (0): Linear (2 -&gt; 2)
  (1): Linear (2 -&gt; 2)
)
1 -&gt; Linear (2 -&gt; 2)
</pre></div></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.modules', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.modules" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">modules</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns an iterator over all modules in the network.</span>
<span class="sd">    Yields:</span>
<span class="sd">        Module: a module in the network</span>
<span class="sd">    Note:</span>
<span class="sd">        Duplicate modules are returned only once. In the following</span>
<span class="sd">        example, ``l`` will be returned only once.</span>
<span class="sd">        &gt;&gt;&gt; l = nn.Linear(2, 2)</span>
<span class="sd">        &gt;&gt;&gt; net = nn.Sequential(l, l)</span>
<span class="sd">        &gt;&gt;&gt; for idx, m in enumerate(net.modules()):</span>
<span class="sd">        &gt;&gt;&gt;     print(idx, &#39;-&gt;&#39;, m)</span>
<span class="sd">        0 -&gt; Sequential (</span>
<span class="sd">          (0): Linear (2 -&gt; 2)</span>
<span class="sd">          (1): Linear (2 -&gt; 2)</span>
<span class="sd">        )</span>
<span class="sd">        1 -&gt; Linear (2 -&gt; 2)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
        <span class="k">yield</span> <span class="n">module</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.named_children">
    <p>def <span class="ident">named_children</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns an iterator over immediate children modules, yielding both
the name of the module as well as the module itself.</p>
<p>Yields:
    (string, Module): Tuple containing a name and child module</p>
<p>Example:
    &gt;&gt;&gt; for name, module in model.named_children():
    &gt;&gt;&gt;     if name in ['conv4', 'conv5']:
    &gt;&gt;&gt;         print(module)</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.named_children', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.named_children" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">named_children</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns an iterator over immediate children modules, yielding both</span>
<span class="sd">    the name of the module as well as the module itself.</span>
<span class="sd">    Yields:</span>
<span class="sd">        (string, Module): Tuple containing a name and child module</span>
<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; for name, module in model.named_children():</span>
<span class="sd">        &gt;&gt;&gt;     if name in [&#39;conv4&#39;, &#39;conv5&#39;]:</span>
<span class="sd">        &gt;&gt;&gt;         print(module)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">memo</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">module</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">module</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">memo</span><span class="p">:</span>
            <span class="n">memo</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.named_modules">
    <p>def <span class="ident">named_modules</span>(</p><p>self, memo=None, prefix=&#39;&#39;)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns an iterator over all modules in the network, yielding
both the name of the module as well as the module itself.</p>
<p>Yields:
    (string, Module): Tuple of name and module</p>
<p>Note:
    Duplicate modules are returned only once. In the following
    example, <code>l</code> will be returned only once.</p>
<div class="codehilite"><pre><span></span>&gt;&gt;&gt; l = nn.Linear(2, 2)
&gt;&gt;&gt; net = nn.Sequential(l, l)
&gt;&gt;&gt; for idx, m in enumerate(net.named_modules()):
&gt;&gt;&gt;     print(idx, &#39;-&gt;&#39;, m)
0 -&gt; (&#39;&#39;, Sequential (
  (0): Linear (2 -&gt; 2)
  (1): Linear (2 -&gt; 2)
))
1 -&gt; (&#39;0&#39;, Linear (2 -&gt; 2))
</pre></div></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.named_modules', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.named_modules" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">named_modules</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">memo</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns an iterator over all modules in the network, yielding</span>
<span class="sd">    both the name of the module as well as the module itself.</span>
<span class="sd">    Yields:</span>
<span class="sd">        (string, Module): Tuple of name and module</span>
<span class="sd">    Note:</span>
<span class="sd">        Duplicate modules are returned only once. In the following</span>
<span class="sd">        example, ``l`` will be returned only once.</span>
<span class="sd">        &gt;&gt;&gt; l = nn.Linear(2, 2)</span>
<span class="sd">        &gt;&gt;&gt; net = nn.Sequential(l, l)</span>
<span class="sd">        &gt;&gt;&gt; for idx, m in enumerate(net.named_modules()):</span>
<span class="sd">        &gt;&gt;&gt;     print(idx, &#39;-&gt;&#39;, m)</span>
<span class="sd">        0 -&gt; (&#39;&#39;, Sequential (</span>
<span class="sd">          (0): Linear (2 -&gt; 2)</span>
<span class="sd">          (1): Linear (2 -&gt; 2)</span>
<span class="sd">        ))</span>
<span class="sd">        1 -&gt; (&#39;0&#39;, Linear (2 -&gt; 2))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">memo</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">memo</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">if</span> <span class="bp">self</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">memo</span><span class="p">:</span>
        <span class="n">memo</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">yield</span> <span class="n">prefix</span><span class="p">,</span> <span class="bp">self</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">module</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">submodule_prefix</span> <span class="o">=</span> <span class="n">prefix</span> <span class="o">+</span> <span class="p">(</span><span class="s1">&#39;.&#39;</span> <span class="k">if</span> <span class="n">prefix</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="n">name</span>
            <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">named_modules</span><span class="p">(</span><span class="n">memo</span><span class="p">,</span> <span class="n">submodule_prefix</span><span class="p">):</span>
                <span class="k">yield</span> <span class="n">m</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.named_parameters">
    <p>def <span class="ident">named_parameters</span>(</p><p>self, memo=None, prefix=&#39;&#39;)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns an iterator over module parameters, yielding both the
name of the parameter as well as the parameter itself</p>
<p>Yields:
    (string, Parameter): Tuple containing the name and parameter</p>
<p>Example:
    &gt;&gt;&gt; for name, param in self.named_parameters():
    &gt;&gt;&gt;    if name in ['bias']:
    &gt;&gt;&gt;        print(param.size())</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.named_parameters', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.named_parameters" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">named_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">memo</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns an iterator over module parameters, yielding both the</span>
<span class="sd">    name of the parameter as well as the parameter itself</span>
<span class="sd">    Yields:</span>
<span class="sd">        (string, Parameter): Tuple containing the name and parameter</span>
<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; for name, param in self.named_parameters():</span>
<span class="sd">        &gt;&gt;&gt;    if name in [&#39;bias&#39;]:</span>
<span class="sd">        &gt;&gt;&gt;        print(param.size())</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">memo</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">memo</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">p</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">p</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">memo</span><span class="p">:</span>
            <span class="n">memo</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">prefix</span> <span class="o">+</span> <span class="p">(</span><span class="s1">&#39;.&#39;</span> <span class="k">if</span> <span class="n">prefix</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span>
    <span class="k">for</span> <span class="n">mname</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
        <span class="n">submodule_prefix</span> <span class="o">=</span> <span class="n">prefix</span> <span class="o">+</span> <span class="p">(</span><span class="s1">&#39;.&#39;</span> <span class="k">if</span> <span class="n">prefix</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="n">mname</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">(</span><span class="n">memo</span><span class="p">,</span> <span class="n">submodule_prefix</span><span class="p">):</span>
            <span class="k">yield</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.parameters">
    <p>def <span class="ident">parameters</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns an iterator over module parameters.</p>
<p>This is typically passed to an optimizer.</p>
<p>Yields:
    Parameter: module parameter</p>
<p>Example:
    &gt;&gt;&gt; for param in model.parameters():
    &gt;&gt;&gt;     print(type(param.data), param.size())
    <class 'torch.FloatTensor'> (20L,)
    <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.parameters', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.parameters" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns an iterator over module parameters.</span>
<span class="sd">    This is typically passed to an optimizer.</span>
<span class="sd">    Yields:</span>
<span class="sd">        Parameter: module parameter</span>
<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; for param in model.parameters():</span>
<span class="sd">        &gt;&gt;&gt;     print(type(param.data), param.size())</span>
<span class="sd">        &lt;class &#39;torch.FloatTensor&#39;&gt; (20L,)</span>
<span class="sd">        &lt;class &#39;torch.FloatTensor&#39;&gt; (20L, 1L, 5L, 5L)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
        <span class="k">yield</span> <span class="n">param</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.register_backward_hook">
    <p>def <span class="ident">register_backward_hook</span>(</p><p>self, hook)</p>
    </div>
    

    
  
    <div class="desc"><p>Registers a backward hook on the module.</p>
<p>The hook will be called every time the gradients with respect to module
inputs are computed. The hook should have the following signature::</p>
<div class="codehilite"><pre><span></span>hook(module, grad_input, grad_output) -&gt; Tensor or None
</pre></div>


<p>The :attr:<code>grad_input</code> and :attr:<code>grad_output</code> may be tuples if the
module has multiple inputs or outputs. The hook should not modify its
arguments, but it can optionally return a new gradient with respect to
input that will be used in place of :attr:<code>grad_input</code> in subsequent
computations.</p>
<p>Returns:
    :class:<code>torch.utils.hooks.RemovableHandle</code>:
        a handle that can be used to remove the added hook by calling
        <code>handle.remove()</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.register_backward_hook', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.register_backward_hook" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">register_backward_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hook</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Registers a backward hook on the module.</span>
<span class="sd">    The hook will be called every time the gradients with respect to module</span>
<span class="sd">    inputs are computed. The hook should have the following signature::</span>
<span class="sd">        hook(module, grad_input, grad_output) -&gt; Tensor or None</span>
<span class="sd">    The :attr:`grad_input` and :attr:`grad_output` may be tuples if the</span>
<span class="sd">    module has multiple inputs or outputs. The hook should not modify its</span>
<span class="sd">    arguments, but it can optionally return a new gradient with respect to</span>
<span class="sd">    input that will be used in place of :attr:`grad_input` in subsequent</span>
<span class="sd">    computations.</span>
<span class="sd">    Returns:</span>
<span class="sd">        :class:`torch.utils.hooks.RemovableHandle`:</span>
<span class="sd">            a handle that can be used to remove the added hook by calling</span>
<span class="sd">            ``handle.remove()``</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">handle</span> <span class="o">=</span> <span class="n">hooks</span><span class="o">.</span><span class="n">RemovableHandle</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span><span class="p">[</span><span class="n">handle</span><span class="o">.</span><span class="n">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">hook</span>
    <span class="k">return</span> <span class="n">handle</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.register_buffer">
    <p>def <span class="ident">register_buffer</span>(</p><p>self, name, tensor)</p>
    </div>
    

    
  
    <div class="desc"><p>Adds a persistent buffer to the module.</p>
<p>This is typically used to register a buffer that should not to be
considered a model parameter. For example, BatchNorm's <code>running_mean</code>
is not a parameter, but is part of the persistent state.</p>
<p>Buffers can be accessed as attributes using given names.</p>
<p>Args:
    name (string): name of the buffer. The buffer can be accessed
        from this module using the given name
    tensor (Tensor): buffer to be registered.</p>
<p>Example:
    &gt;&gt;&gt; self.register_buffer('running_mean', torch.zeros(num_features))</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.register_buffer', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.register_buffer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">register_buffer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Adds a persistent buffer to the module.</span>
<span class="sd">    This is typically used to register a buffer that should not to be</span>
<span class="sd">    considered a model parameter. For example, BatchNorm&#39;s ``running_mean``</span>
<span class="sd">    is not a parameter, but is part of the persistent state.</span>
<span class="sd">    Buffers can be accessed as attributes using given names.</span>
<span class="sd">    Args:</span>
<span class="sd">        name (string): name of the buffer. The buffer can be accessed</span>
<span class="sd">            from this module using the given name</span>
<span class="sd">        tensor (Tensor): buffer to be registered.</span>
<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; self.register_buffer(&#39;running_mean&#39;, torch.zeros(num_features))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_buffers</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;attribute &#39;{}&#39; already exists&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_buffers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">tensor</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.register_forward_hook">
    <p>def <span class="ident">register_forward_hook</span>(</p><p>self, hook)</p>
    </div>
    

    
  
    <div class="desc"><p>Registers a forward hook on the module.</p>
<p>The hook will be called every time after :func:<code>forward</code> has computed an output.
It should have the following signature::</p>
<div class="codehilite"><pre><span></span>hook(module, input, output) -&gt; None
</pre></div>


<p>The hook should not modify the input or output.</p>
<p>Returns:
    :class:<code>torch.utils.hooks.RemovableHandle</code>:
        a handle that can be used to remove the added hook by calling
        <code>handle.remove()</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.register_forward_hook', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.register_forward_hook" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">register_forward_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hook</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Registers a forward hook on the module.</span>
<span class="sd">    The hook will be called every time after :func:`forward` has computed an output.</span>
<span class="sd">    It should have the following signature::</span>
<span class="sd">        hook(module, input, output) -&gt; None</span>
<span class="sd">    The hook should not modify the input or output.</span>
<span class="sd">    Returns:</span>
<span class="sd">        :class:`torch.utils.hooks.RemovableHandle`:</span>
<span class="sd">            a handle that can be used to remove the added hook by calling</span>
<span class="sd">            ``handle.remove()``</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">handle</span> <span class="o">=</span> <span class="n">hooks</span><span class="o">.</span><span class="n">RemovableHandle</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span><span class="p">[</span><span class="n">handle</span><span class="o">.</span><span class="n">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">hook</span>
    <span class="k">return</span> <span class="n">handle</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.register_forward_pre_hook">
    <p>def <span class="ident">register_forward_pre_hook</span>(</p><p>self, hook)</p>
    </div>
    

    
  
    <div class="desc"><p>Registers a forward pre-hook on the module.</p>
<p>The hook will be called every time before :func:<code>forward</code> is invoked.
It should have the following signature::</p>
<div class="codehilite"><pre><span></span>hook(module, input) -&gt; None
</pre></div>


<p>The hook should not modify the input.</p>
<p>Returns:
    :class:<code>torch.utils.hooks.RemovableHandle</code>:
        a handle that can be used to remove the added hook by calling
        <code>handle.remove()</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.register_forward_pre_hook', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.register_forward_pre_hook" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">register_forward_pre_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hook</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Registers a forward pre-hook on the module.</span>
<span class="sd">    The hook will be called every time before :func:`forward` is invoked.</span>
<span class="sd">    It should have the following signature::</span>
<span class="sd">        hook(module, input) -&gt; None</span>
<span class="sd">    The hook should not modify the input.</span>
<span class="sd">    Returns:</span>
<span class="sd">        :class:`torch.utils.hooks.RemovableHandle`:</span>
<span class="sd">            a handle that can be used to remove the added hook by calling</span>
<span class="sd">            ``handle.remove()``</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">handle</span> <span class="o">=</span> <span class="n">hooks</span><span class="o">.</span><span class="n">RemovableHandle</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span><span class="p">[</span><span class="n">handle</span><span class="o">.</span><span class="n">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">hook</span>
    <span class="k">return</span> <span class="n">handle</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.register_parameter">
    <p>def <span class="ident">register_parameter</span>(</p><p>self, name, param)</p>
    </div>
    

    
  
    <div class="desc"><p>Adds a parameter to the module.</p>
<p>The parameter can be accessed as an attribute using given name.</p>
<p>Args:
    name (string): name of the parameter. The parameter can be accessed
        from this module using the given name
    parameter (Parameter): parameter to be added to the module.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.register_parameter', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.register_parameter" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">register_parameter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Adds a parameter to the module.</span>
<span class="sd">    The parameter can be accessed as an attribute using given name.</span>
<span class="sd">    Args:</span>
<span class="sd">        name (string): name of the parameter. The parameter can be accessed</span>
<span class="sd">            from this module using the given name</span>
<span class="sd">        parameter (Parameter): parameter to be added to the module.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="s1">&#39;_parameters&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
            <span class="s2">&quot;cannot assign parameter before Module.__init__() call&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;attribute &#39;{}&#39; already exists&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">param</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;cannot assign &#39;{}&#39; object to parameter &#39;{}&#39; &quot;</span>
                        <span class="s2">&quot;(torch.nn.Parameter or None required)&quot;</span>
                        <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">typename</span><span class="p">(</span><span class="n">param</span><span class="p">),</span> <span class="n">name</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">param</span><span class="o">.</span><span class="n">grad_fn</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Cannot assign non-leaf Variable to parameter &#39;{0}&#39;. Model &quot;</span>
            <span class="s2">&quot;parameters must be created explicitly. To express &#39;{0}&#39; &quot;</span>
            <span class="s2">&quot;as a function of another variable, compute the value in &quot;</span>
            <span class="s2">&quot;the forward() method.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.share_memory">
    <p>def <span class="ident">share_memory</span>(</p><p>self)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.share_memory', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.share_memory" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">share_memory</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">share_memory_</span><span class="p">())</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.state_dict">
    <p>def <span class="ident">state_dict</span>(</p><p>self, destination=None, prefix=&#39;&#39;, keep_vars=False)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns a dictionary containing a whole state of the module.</p>
<p>Both parameters and persistent buffers (e.g. running averages) are
included. Keys are corresponding parameter and buffer names.</p>
<p>When keep_vars is <code>True</code>, it returns a Variable for each parameter
(rather than a Tensor).</p>
<p>Args:
    destination (dict, optional):
        if not None, the return dictionary is stored into destination.
        Default: None
    prefix (string, optional): Adds a prefix to the key (name) of every
        parameter and buffer in the result dictionary. Default: ''
    keep_vars (bool, optional): if <code>True</code>, returns a Variable for each
        parameter. If <code>False</code>, returns a Tensor for each parameter.
        Default: <code>False</code></p>
<p>Returns:
    dict:
        a dictionary containing a whole state of the module</p>
<p>Example:
    &gt;&gt;&gt; module.state_dict().keys()
    ['bias', 'weight']</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.state_dict', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.state_dict" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">destination</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">keep_vars</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a dictionary containing a whole state of the module.</span>
<span class="sd">    Both parameters and persistent buffers (e.g. running averages) are</span>
<span class="sd">    included. Keys are corresponding parameter and buffer names.</span>
<span class="sd">    When keep_vars is ``True``, it returns a Variable for each parameter</span>
<span class="sd">    (rather than a Tensor).</span>
<span class="sd">    Args:</span>
<span class="sd">        destination (dict, optional):</span>
<span class="sd">            if not None, the return dictionary is stored into destination.</span>
<span class="sd">            Default: None</span>
<span class="sd">        prefix (string, optional): Adds a prefix to the key (name) of every</span>
<span class="sd">            parameter and buffer in the result dictionary. Default: &#39;&#39;</span>
<span class="sd">        keep_vars (bool, optional): if ``True``, returns a Variable for each</span>
<span class="sd">            parameter. If ``False``, returns a Tensor for each parameter.</span>
<span class="sd">            Default: ``False``</span>
<span class="sd">    Returns:</span>
<span class="sd">        dict:</span>
<span class="sd">            a dictionary containing a whole state of the module</span>
<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; module.state_dict().keys()</span>
<span class="sd">        [&#39;bias&#39;, &#39;weight&#39;]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">destination</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">destination</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">param</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">destination</span><span class="p">[</span><span class="n">prefix</span> <span class="o">+</span> <span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span> <span class="k">if</span> <span class="n">keep_vars</span> <span class="k">else</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">buf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_buffers</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">buf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">destination</span><span class="p">[</span><span class="n">prefix</span> <span class="o">+</span> <span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">buf</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">module</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">module</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(</span><span class="n">destination</span><span class="p">,</span> <span class="n">prefix</span> <span class="o">+</span> <span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">keep_vars</span><span class="o">=</span><span class="n">keep_vars</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">destination</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.train">
    <p>def <span class="ident">train</span>(</p><p>self, mode=True)</p>
    </div>
    

    
  
    <div class="desc"><p>Sets the module in training mode.</p>
<p>This has any effect only on modules such as Dropout or BatchNorm.</p>
<p>Returns:
    Module: self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.train', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.train" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets the module in training mode.</span>
<span class="sd">    This has any effect only on modules such as Dropout or BatchNorm.</span>
<span class="sd">    Returns:</span>
<span class="sd">        Module: self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="o">=</span> <span class="n">mode</span>
    <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">():</span>
        <span class="n">module</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.type">
    <p>def <span class="ident">type</span>(</p><p>self, dst_type)</p>
    </div>
    

    
  
    <div class="desc"><p>Casts all parameters and buffers to dst_type.</p>
<p>Arguments:
    dst_type (type or string): the desired type</p>
<p>Returns:
    Module: self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.type', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.type" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">type</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dst_type</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Casts all parameters and buffers to dst_type.</span>
<span class="sd">    Arguments:</span>
<span class="sd">        dst_type (type or string): the desired type</span>
<span class="sd">    Returns:</span>
<span class="sd">        Module: self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">dst_type</span><span class="p">))</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.FFNNClassificationNN.zero_grad">
    <p>def <span class="ident">zero_grad</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Sets gradients of all model parameters to zero.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.FFNNClassificationNN.zero_grad', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.FFNNClassificationNN.zero_grad" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets gradients of all model parameters to zero.&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">volatile</span><span class="p">:</span>
                <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span>
                <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">new</span><span class="p">()</span><span class="o">.</span><span class="n">resize_as_</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">zero_</span><span class="p">())</span>
</pre></div>

  </div>
</div>

  </div>
  
          <h3>Instance variables</h3>
            <div class="item">
            <p id="noxer.nn.FFNNClassificationNN.fc" class="name">var <span class="ident">fc</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
      </div>
      </div>
      
      <div class="item">
      <p id="noxer.nn.GRUClassification" class="name">class <span class="ident">GRUClassification</span></p>
      
  
    <div class="desc"><p>Recurent neural network module. Maps sequence to vector output.</p>
<h2>Parameters</h2>
<p>xsz: int &gt; 0
    Size of input vector</p>
<p>ysz: int &gt; 0
    Size of output vector</p>
<p>n_layers: int &gt; 0
    Number of layers in the neural network</p>
<p>n_neurons: int &gt; 0
    Number of neurons in every layer</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification" class="source">
    <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">GRUClassification</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Recurent neural network module. Maps sequence to vector output.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    xsz: int &gt; 0</span>
<span class="sd">        Size of input vector</span>

<span class="sd">    ysz: int &gt; 0</span>
<span class="sd">        Size of output vector</span>

<span class="sd">    n_layers: int &gt; 0</span>
<span class="sd">        Number of layers in the neural network</span>

<span class="sd">    n_neurons: int &gt; 0</span>
<span class="sd">        Number of neurons in every layer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xsz</span><span class="p">,</span> <span class="n">ysz</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GRUClassification</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">ssz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">xsz</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">hsz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">xsz</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">ysz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">ysz</span><span class="p">)</span>
        <span class="n">n_neurons</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span>
        <span class="n">n_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">dropout</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">hsz</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="c1"># calculate flatten</span>
        <span class="n">hsz</span> <span class="o">=</span> <span class="n">n_neurons</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">ffnn</span> <span class="o">=</span> <span class="n">FFNNClassificationNN</span><span class="p">(</span><span class="n">hsz</span><span class="p">,</span> <span class="n">ysz</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="n">n_neurons</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># swap to (seq_len, batch, input_size)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># flatten the data</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffnn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>

  </div>
</div>


      <div class="class">
          <h3>Ancestors (in MRO)</h3>
          <ul class="class_list">
          <li><a href="#noxer.nn.GRUClassification">GRUClassification</a></li>
          <li>torch.nn.modules.module.Module</li>
          <li>builtins.object</li>
          </ul>
          <h3>Class variables</h3>
            <div class="item">
            <p id="noxer.nn.GRUClassification.dump_patches" class="name">var <span class="ident">dump_patches</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
          <h3>Static methods</h3>
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.__init__">
    <p>def <span class="ident">__init__</span>(</p><p>self, xsz, ysz, n_neurons=64, n_layers=1, dropout=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Initialize self.  See help(type(self)) for accurate signature.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.__init__', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.__init__" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xsz</span><span class="p">,</span> <span class="n">ysz</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">GRUClassification</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="n">ssz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">xsz</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">hsz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">xsz</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">ysz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">ysz</span><span class="p">)</span>
    <span class="n">n_neurons</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span>
    <span class="n">n_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">dropout</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">hsz</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
    <span class="c1"># calculate flatten</span>
    <span class="n">hsz</span> <span class="o">=</span> <span class="n">n_neurons</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ffnn</span> <span class="o">=</span> <span class="n">FFNNClassificationNN</span><span class="p">(</span><span class="n">hsz</span><span class="p">,</span> <span class="n">ysz</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="n">n_neurons</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.add_module">
    <p>def <span class="ident">add_module</span>(</p><p>self, name, module)</p>
    </div>
    

    
  
    <div class="desc"><p>Adds a child module to the current module.</p>
<p>The module can be accessed as an attribute using the given name.</p>
<p>Args:
    name (string): name of the child module. The child module can be
        accessed from this module using the given name
    parameter (Module): child module to be added to the module.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.add_module', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.add_module" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">add_module</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Adds a child module to the current module.</span>
<span class="sd">    The module can be accessed as an attribute using the given name.</span>
<span class="sd">    Args:</span>
<span class="sd">        name (string): name of the child module. The child module can be</span>
<span class="sd">            accessed from this module using the given name</span>
<span class="sd">        parameter (Module): child module to be added to the module.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">Module</span><span class="p">)</span> <span class="ow">and</span> <span class="n">module</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;{} is not a Module subclass&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">typename</span><span class="p">(</span><span class="n">module</span><span class="p">)))</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;attribute &#39;{}&#39; already exists&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">module</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.apply">
    <p>def <span class="ident">apply</span>(</p><p>self, fn)</p>
    </div>
    

    
  
    <div class="desc"><p>Applies <code>fn</code> recursively to every submodule (as returned by <code>.children()</code>)
as well as self. Typical use includes initializing the parameters of a model
(see also :ref:<code>torch-nn-init</code>).</p>
<p>Args:
    fn (:class:<code>Module</code> -&gt; None): function to be applied to each submodule</p>
<p>Returns:
    Module: self</p>
<p>Example:
    &gt;&gt;&gt; def init_weights(m):
    &gt;&gt;&gt;     print(m)
    &gt;&gt;&gt;     if type(m) == nn.Linear:
    &gt;&gt;&gt;         m.weight.data.fill_(1.0)
    &gt;&gt;&gt;         print(m.weight)
    &gt;&gt;&gt;
    &gt;&gt;&gt; net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))
    &gt;&gt;&gt; net.apply(init_weights)
    Linear (2 -&gt; 2)
    Parameter containing:
     1  1
     1  1
    [torch.FloatTensor of size 2x2]
    Linear (2 -&gt; 2)
    Parameter containing:
     1  1
     1  1
    [torch.FloatTensor of size 2x2]
    Sequential (
      (0): Linear (2 -&gt; 2)
      (1): Linear (2 -&gt; 2)
    )</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.apply', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.apply" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Applies ``fn`` recursively to every submodule (as returned by ``.children()``)</span>
<span class="sd">    as well as self. Typical use includes initializing the parameters of a model</span>
<span class="sd">    (see also :ref:`torch-nn-init`).</span>
<span class="sd">    Args:</span>
<span class="sd">        fn (:class:`Module` -&gt; None): function to be applied to each submodule</span>
<span class="sd">    Returns:</span>
<span class="sd">        Module: self</span>
<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; def init_weights(m):</span>
<span class="sd">        &gt;&gt;&gt;     print(m)</span>
<span class="sd">        &gt;&gt;&gt;     if type(m) == nn.Linear:</span>
<span class="sd">        &gt;&gt;&gt;         m.weight.data.fill_(1.0)</span>
<span class="sd">        &gt;&gt;&gt;         print(m.weight)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))</span>
<span class="sd">        &gt;&gt;&gt; net.apply(init_weights)</span>
<span class="sd">        Linear (2 -&gt; 2)</span>
<span class="sd">        Parameter containing:</span>
<span class="sd">         1  1</span>
<span class="sd">         1  1</span>
<span class="sd">        [torch.FloatTensor of size 2x2]</span>
<span class="sd">        Linear (2 -&gt; 2)</span>
<span class="sd">        Parameter containing:</span>
<span class="sd">         1  1</span>
<span class="sd">         1  1</span>
<span class="sd">        [torch.FloatTensor of size 2x2]</span>
<span class="sd">        Sequential (</span>
<span class="sd">          (0): Linear (2 -&gt; 2)</span>
<span class="sd">          (1): Linear (2 -&gt; 2)</span>
<span class="sd">        )</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">():</span>
        <span class="n">module</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="n">fn</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.children">
    <p>def <span class="ident">children</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns an iterator over immediate children modules.</p>
<p>Yields:
    Module: a child module</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.children', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.children" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">children</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns an iterator over immediate children modules.</span>
<span class="sd">    Yields:</span>
<span class="sd">        Module: a child module</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
        <span class="k">yield</span> <span class="n">module</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.cpu">
    <p>def <span class="ident">cpu</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Moves all model parameters and buffers to the CPU.</p>
<p>Returns:
    Module: self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.cpu', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.cpu" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">cpu</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Moves all model parameters and buffers to the CPU.</span>
<span class="sd">    Returns:</span>
<span class="sd">        Module: self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.cuda">
    <p>def <span class="ident">cuda</span>(</p><p>self, device=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Moves all model parameters and buffers to the GPU.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on GPU while being optimized.</p>
<p>Arguments:
    device (int, optional): if specified, all parameters will be
        copied to that device</p>
<p>Returns:
    Module: self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.cuda', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.cuda" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">cuda</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Moves all model parameters and buffers to the GPU.</span>
<span class="sd">    This also makes associated parameters and buffers different objects. So</span>
<span class="sd">    it should be called before constructing optimizer if the module will</span>
<span class="sd">    live on GPU while being optimized.</span>
<span class="sd">    Arguments:</span>
<span class="sd">        device (int, optional): if specified, all parameters will be</span>
<span class="sd">            copied to that device</span>
<span class="sd">    Returns:</span>
<span class="sd">        Module: self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.double">
    <p>def <span class="ident">double</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Casts all parameters and buffers to double datatype.</p>
<p>Returns:
    Module: self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.double', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.double" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">double</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Casts all parameters and buffers to double datatype.</span>
<span class="sd">    Returns:</span>
<span class="sd">        Module: self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">double</span><span class="p">())</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.eval">
    <p>def <span class="ident">eval</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Sets the module in evaluation mode.</p>
<p>This has any effect only on modules such as Dropout or BatchNorm.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.eval', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.eval" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">eval</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets the module in evaluation mode.</span>
<span class="sd">    This has any effect only on modules such as Dropout or BatchNorm.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.float">
    <p>def <span class="ident">float</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Casts all parameters and buffers to float datatype.</p>
<p>Returns:
    Module: self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.float', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.float" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">float</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Casts all parameters and buffers to float datatype.</span>
<span class="sd">    Returns:</span>
<span class="sd">        Module: self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.forward">
    <p>def <span class="ident">forward</span>(</p><p>self, x)</p>
    </div>
    

    
  
    <div class="desc"><p>Defines the computation performed at every call.</p>
<p>Should be overriden by all subclasses.</p>
<p>.. note::
    Although the recipe for forward pass needs to be defined within
    this function, one should call the :class:<code>Module</code> instance afterwards
    instead of this since the former takes care of running the
    registered hooks while the latter silently ignores them.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.forward', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.forward" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="c1"># swap to (seq_len, batch, input_size)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1"># flatten the data</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffnn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.half">
    <p>def <span class="ident">half</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Casts all parameters and buffers to half datatype.</p>
<p>Returns:
    Module: self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.half', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.half" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">half</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Casts all parameters and buffers to half datatype.</span>
<span class="sd">    Returns:</span>
<span class="sd">        Module: self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">half</span><span class="p">())</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.load_state_dict">
    <p>def <span class="ident">load_state_dict</span>(</p><p>self, state_dict, strict=True)</p>
    </div>
    

    
  
    <div class="desc"><p>Copies parameters and buffers from :attr:<code>state_dict</code> into
this module and its descendants. If :attr:<code>strict</code> is <code>True</code> then
the keys of :attr:<code>state_dict</code> must exactly match the keys returned
by this module's :func:<code>state_dict()</code> function.</p>
<p>Arguments:
    state_dict (dict): A dict containing parameters and
        persistent buffers.
    strict (bool): Strictly enforce that the keys in :attr:<code>state_dict</code>
        match the keys returned by this module's <code>:func:</code>state_dict()`
        function.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.load_state_dict', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.load_state_dict" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Copies parameters and buffers from :attr:`state_dict` into</span>
<span class="sd">    this module and its descendants. If :attr:`strict` is ``True`` then</span>
<span class="sd">    the keys of :attr:`state_dict` must exactly match the keys returned</span>
<span class="sd">    by this module&#39;s :func:`state_dict()` function.</span>
<span class="sd">    Arguments:</span>
<span class="sd">        state_dict (dict): A dict containing parameters and</span>
<span class="sd">            persistent buffers.</span>
<span class="sd">        strict (bool): Strictly enforce that the keys in :attr:`state_dict`</span>
<span class="sd">            match the keys returned by this module&#39;s `:func:`state_dict()`</span>
<span class="sd">            function.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">own_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">own_state</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">):</span>
                <span class="c1"># backwards compatibility for serialized parameters</span>
                <span class="n">param</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">own_state</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;While copying the parameter named {}, &#39;</span>
                                   <span class="s1">&#39;whose dimensions in the model are {} and &#39;</span>
                                   <span class="s1">&#39;whose dimensions in the checkpoint are {}.&#39;</span>
                                   <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">own_state</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">()))</span>
        <span class="k">elif</span> <span class="n">strict</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s1">&#39;unexpected key &quot;{}&quot; in state_dict&#39;</span>
                           <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">strict</span><span class="p">:</span>
        <span class="n">missing</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">own_state</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">state_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">missing</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s1">&#39;missing keys in state_dict: &quot;{}&quot;&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">missing</span><span class="p">))</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.modules">
    <p>def <span class="ident">modules</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns an iterator over all modules in the network.</p>
<p>Yields:
    Module: a module in the network</p>
<p>Note:
    Duplicate modules are returned only once. In the following
    example, <code>l</code> will be returned only once.</p>
<div class="codehilite"><pre><span></span>&gt;&gt;&gt; l = nn.Linear(2, 2)
&gt;&gt;&gt; net = nn.Sequential(l, l)
&gt;&gt;&gt; for idx, m in enumerate(net.modules()):
&gt;&gt;&gt;     print(idx, &#39;-&gt;&#39;, m)
0 -&gt; Sequential (
  (0): Linear (2 -&gt; 2)
  (1): Linear (2 -&gt; 2)
)
1 -&gt; Linear (2 -&gt; 2)
</pre></div></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.modules', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.modules" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">modules</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns an iterator over all modules in the network.</span>
<span class="sd">    Yields:</span>
<span class="sd">        Module: a module in the network</span>
<span class="sd">    Note:</span>
<span class="sd">        Duplicate modules are returned only once. In the following</span>
<span class="sd">        example, ``l`` will be returned only once.</span>
<span class="sd">        &gt;&gt;&gt; l = nn.Linear(2, 2)</span>
<span class="sd">        &gt;&gt;&gt; net = nn.Sequential(l, l)</span>
<span class="sd">        &gt;&gt;&gt; for idx, m in enumerate(net.modules()):</span>
<span class="sd">        &gt;&gt;&gt;     print(idx, &#39;-&gt;&#39;, m)</span>
<span class="sd">        0 -&gt; Sequential (</span>
<span class="sd">          (0): Linear (2 -&gt; 2)</span>
<span class="sd">          (1): Linear (2 -&gt; 2)</span>
<span class="sd">        )</span>
<span class="sd">        1 -&gt; Linear (2 -&gt; 2)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
        <span class="k">yield</span> <span class="n">module</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.named_children">
    <p>def <span class="ident">named_children</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns an iterator over immediate children modules, yielding both
the name of the module as well as the module itself.</p>
<p>Yields:
    (string, Module): Tuple containing a name and child module</p>
<p>Example:
    &gt;&gt;&gt; for name, module in model.named_children():
    &gt;&gt;&gt;     if name in ['conv4', 'conv5']:
    &gt;&gt;&gt;         print(module)</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.named_children', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.named_children" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">named_children</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns an iterator over immediate children modules, yielding both</span>
<span class="sd">    the name of the module as well as the module itself.</span>
<span class="sd">    Yields:</span>
<span class="sd">        (string, Module): Tuple containing a name and child module</span>
<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; for name, module in model.named_children():</span>
<span class="sd">        &gt;&gt;&gt;     if name in [&#39;conv4&#39;, &#39;conv5&#39;]:</span>
<span class="sd">        &gt;&gt;&gt;         print(module)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">memo</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">module</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">module</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">memo</span><span class="p">:</span>
            <span class="n">memo</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.named_modules">
    <p>def <span class="ident">named_modules</span>(</p><p>self, memo=None, prefix=&#39;&#39;)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns an iterator over all modules in the network, yielding
both the name of the module as well as the module itself.</p>
<p>Yields:
    (string, Module): Tuple of name and module</p>
<p>Note:
    Duplicate modules are returned only once. In the following
    example, <code>l</code> will be returned only once.</p>
<div class="codehilite"><pre><span></span>&gt;&gt;&gt; l = nn.Linear(2, 2)
&gt;&gt;&gt; net = nn.Sequential(l, l)
&gt;&gt;&gt; for idx, m in enumerate(net.named_modules()):
&gt;&gt;&gt;     print(idx, &#39;-&gt;&#39;, m)
0 -&gt; (&#39;&#39;, Sequential (
  (0): Linear (2 -&gt; 2)
  (1): Linear (2 -&gt; 2)
))
1 -&gt; (&#39;0&#39;, Linear (2 -&gt; 2))
</pre></div></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.named_modules', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.named_modules" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">named_modules</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">memo</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns an iterator over all modules in the network, yielding</span>
<span class="sd">    both the name of the module as well as the module itself.</span>
<span class="sd">    Yields:</span>
<span class="sd">        (string, Module): Tuple of name and module</span>
<span class="sd">    Note:</span>
<span class="sd">        Duplicate modules are returned only once. In the following</span>
<span class="sd">        example, ``l`` will be returned only once.</span>
<span class="sd">        &gt;&gt;&gt; l = nn.Linear(2, 2)</span>
<span class="sd">        &gt;&gt;&gt; net = nn.Sequential(l, l)</span>
<span class="sd">        &gt;&gt;&gt; for idx, m in enumerate(net.named_modules()):</span>
<span class="sd">        &gt;&gt;&gt;     print(idx, &#39;-&gt;&#39;, m)</span>
<span class="sd">        0 -&gt; (&#39;&#39;, Sequential (</span>
<span class="sd">          (0): Linear (2 -&gt; 2)</span>
<span class="sd">          (1): Linear (2 -&gt; 2)</span>
<span class="sd">        ))</span>
<span class="sd">        1 -&gt; (&#39;0&#39;, Linear (2 -&gt; 2))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">memo</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">memo</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">if</span> <span class="bp">self</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">memo</span><span class="p">:</span>
        <span class="n">memo</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">yield</span> <span class="n">prefix</span><span class="p">,</span> <span class="bp">self</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">module</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">submodule_prefix</span> <span class="o">=</span> <span class="n">prefix</span> <span class="o">+</span> <span class="p">(</span><span class="s1">&#39;.&#39;</span> <span class="k">if</span> <span class="n">prefix</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="n">name</span>
            <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">named_modules</span><span class="p">(</span><span class="n">memo</span><span class="p">,</span> <span class="n">submodule_prefix</span><span class="p">):</span>
                <span class="k">yield</span> <span class="n">m</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.named_parameters">
    <p>def <span class="ident">named_parameters</span>(</p><p>self, memo=None, prefix=&#39;&#39;)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns an iterator over module parameters, yielding both the
name of the parameter as well as the parameter itself</p>
<p>Yields:
    (string, Parameter): Tuple containing the name and parameter</p>
<p>Example:
    &gt;&gt;&gt; for name, param in self.named_parameters():
    &gt;&gt;&gt;    if name in ['bias']:
    &gt;&gt;&gt;        print(param.size())</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.named_parameters', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.named_parameters" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">named_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">memo</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns an iterator over module parameters, yielding both the</span>
<span class="sd">    name of the parameter as well as the parameter itself</span>
<span class="sd">    Yields:</span>
<span class="sd">        (string, Parameter): Tuple containing the name and parameter</span>
<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; for name, param in self.named_parameters():</span>
<span class="sd">        &gt;&gt;&gt;    if name in [&#39;bias&#39;]:</span>
<span class="sd">        &gt;&gt;&gt;        print(param.size())</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">memo</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">memo</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">p</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">p</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">memo</span><span class="p">:</span>
            <span class="n">memo</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">prefix</span> <span class="o">+</span> <span class="p">(</span><span class="s1">&#39;.&#39;</span> <span class="k">if</span> <span class="n">prefix</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span>
    <span class="k">for</span> <span class="n">mname</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
        <span class="n">submodule_prefix</span> <span class="o">=</span> <span class="n">prefix</span> <span class="o">+</span> <span class="p">(</span><span class="s1">&#39;.&#39;</span> <span class="k">if</span> <span class="n">prefix</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="n">mname</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">(</span><span class="n">memo</span><span class="p">,</span> <span class="n">submodule_prefix</span><span class="p">):</span>
            <span class="k">yield</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.parameters">
    <p>def <span class="ident">parameters</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns an iterator over module parameters.</p>
<p>This is typically passed to an optimizer.</p>
<p>Yields:
    Parameter: module parameter</p>
<p>Example:
    &gt;&gt;&gt; for param in model.parameters():
    &gt;&gt;&gt;     print(type(param.data), param.size())
    <class 'torch.FloatTensor'> (20L,)
    <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.parameters', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.parameters" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns an iterator over module parameters.</span>
<span class="sd">    This is typically passed to an optimizer.</span>
<span class="sd">    Yields:</span>
<span class="sd">        Parameter: module parameter</span>
<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; for param in model.parameters():</span>
<span class="sd">        &gt;&gt;&gt;     print(type(param.data), param.size())</span>
<span class="sd">        &lt;class &#39;torch.FloatTensor&#39;&gt; (20L,)</span>
<span class="sd">        &lt;class &#39;torch.FloatTensor&#39;&gt; (20L, 1L, 5L, 5L)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
        <span class="k">yield</span> <span class="n">param</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.register_backward_hook">
    <p>def <span class="ident">register_backward_hook</span>(</p><p>self, hook)</p>
    </div>
    

    
  
    <div class="desc"><p>Registers a backward hook on the module.</p>
<p>The hook will be called every time the gradients with respect to module
inputs are computed. The hook should have the following signature::</p>
<div class="codehilite"><pre><span></span>hook(module, grad_input, grad_output) -&gt; Tensor or None
</pre></div>


<p>The :attr:<code>grad_input</code> and :attr:<code>grad_output</code> may be tuples if the
module has multiple inputs or outputs. The hook should not modify its
arguments, but it can optionally return a new gradient with respect to
input that will be used in place of :attr:<code>grad_input</code> in subsequent
computations.</p>
<p>Returns:
    :class:<code>torch.utils.hooks.RemovableHandle</code>:
        a handle that can be used to remove the added hook by calling
        <code>handle.remove()</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.register_backward_hook', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.register_backward_hook" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">register_backward_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hook</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Registers a backward hook on the module.</span>
<span class="sd">    The hook will be called every time the gradients with respect to module</span>
<span class="sd">    inputs are computed. The hook should have the following signature::</span>
<span class="sd">        hook(module, grad_input, grad_output) -&gt; Tensor or None</span>
<span class="sd">    The :attr:`grad_input` and :attr:`grad_output` may be tuples if the</span>
<span class="sd">    module has multiple inputs or outputs. The hook should not modify its</span>
<span class="sd">    arguments, but it can optionally return a new gradient with respect to</span>
<span class="sd">    input that will be used in place of :attr:`grad_input` in subsequent</span>
<span class="sd">    computations.</span>
<span class="sd">    Returns:</span>
<span class="sd">        :class:`torch.utils.hooks.RemovableHandle`:</span>
<span class="sd">            a handle that can be used to remove the added hook by calling</span>
<span class="sd">            ``handle.remove()``</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">handle</span> <span class="o">=</span> <span class="n">hooks</span><span class="o">.</span><span class="n">RemovableHandle</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span><span class="p">[</span><span class="n">handle</span><span class="o">.</span><span class="n">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">hook</span>
    <span class="k">return</span> <span class="n">handle</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.register_buffer">
    <p>def <span class="ident">register_buffer</span>(</p><p>self, name, tensor)</p>
    </div>
    

    
  
    <div class="desc"><p>Adds a persistent buffer to the module.</p>
<p>This is typically used to register a buffer that should not to be
considered a model parameter. For example, BatchNorm's <code>running_mean</code>
is not a parameter, but is part of the persistent state.</p>
<p>Buffers can be accessed as attributes using given names.</p>
<p>Args:
    name (string): name of the buffer. The buffer can be accessed
        from this module using the given name
    tensor (Tensor): buffer to be registered.</p>
<p>Example:
    &gt;&gt;&gt; self.register_buffer('running_mean', torch.zeros(num_features))</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.register_buffer', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.register_buffer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">register_buffer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Adds a persistent buffer to the module.</span>
<span class="sd">    This is typically used to register a buffer that should not to be</span>
<span class="sd">    considered a model parameter. For example, BatchNorm&#39;s ``running_mean``</span>
<span class="sd">    is not a parameter, but is part of the persistent state.</span>
<span class="sd">    Buffers can be accessed as attributes using given names.</span>
<span class="sd">    Args:</span>
<span class="sd">        name (string): name of the buffer. The buffer can be accessed</span>
<span class="sd">            from this module using the given name</span>
<span class="sd">        tensor (Tensor): buffer to be registered.</span>
<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; self.register_buffer(&#39;running_mean&#39;, torch.zeros(num_features))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_buffers</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;attribute &#39;{}&#39; already exists&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_buffers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">tensor</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.register_forward_hook">
    <p>def <span class="ident">register_forward_hook</span>(</p><p>self, hook)</p>
    </div>
    

    
  
    <div class="desc"><p>Registers a forward hook on the module.</p>
<p>The hook will be called every time after :func:<code>forward</code> has computed an output.
It should have the following signature::</p>
<div class="codehilite"><pre><span></span>hook(module, input, output) -&gt; None
</pre></div>


<p>The hook should not modify the input or output.</p>
<p>Returns:
    :class:<code>torch.utils.hooks.RemovableHandle</code>:
        a handle that can be used to remove the added hook by calling
        <code>handle.remove()</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.register_forward_hook', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.register_forward_hook" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">register_forward_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hook</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Registers a forward hook on the module.</span>
<span class="sd">    The hook will be called every time after :func:`forward` has computed an output.</span>
<span class="sd">    It should have the following signature::</span>
<span class="sd">        hook(module, input, output) -&gt; None</span>
<span class="sd">    The hook should not modify the input or output.</span>
<span class="sd">    Returns:</span>
<span class="sd">        :class:`torch.utils.hooks.RemovableHandle`:</span>
<span class="sd">            a handle that can be used to remove the added hook by calling</span>
<span class="sd">            ``handle.remove()``</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">handle</span> <span class="o">=</span> <span class="n">hooks</span><span class="o">.</span><span class="n">RemovableHandle</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span><span class="p">[</span><span class="n">handle</span><span class="o">.</span><span class="n">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">hook</span>
    <span class="k">return</span> <span class="n">handle</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.register_forward_pre_hook">
    <p>def <span class="ident">register_forward_pre_hook</span>(</p><p>self, hook)</p>
    </div>
    

    
  
    <div class="desc"><p>Registers a forward pre-hook on the module.</p>
<p>The hook will be called every time before :func:<code>forward</code> is invoked.
It should have the following signature::</p>
<div class="codehilite"><pre><span></span>hook(module, input) -&gt; None
</pre></div>


<p>The hook should not modify the input.</p>
<p>Returns:
    :class:<code>torch.utils.hooks.RemovableHandle</code>:
        a handle that can be used to remove the added hook by calling
        <code>handle.remove()</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.register_forward_pre_hook', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.register_forward_pre_hook" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">register_forward_pre_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hook</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Registers a forward pre-hook on the module.</span>
<span class="sd">    The hook will be called every time before :func:`forward` is invoked.</span>
<span class="sd">    It should have the following signature::</span>
<span class="sd">        hook(module, input) -&gt; None</span>
<span class="sd">    The hook should not modify the input.</span>
<span class="sd">    Returns:</span>
<span class="sd">        :class:`torch.utils.hooks.RemovableHandle`:</span>
<span class="sd">            a handle that can be used to remove the added hook by calling</span>
<span class="sd">            ``handle.remove()``</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">handle</span> <span class="o">=</span> <span class="n">hooks</span><span class="o">.</span><span class="n">RemovableHandle</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span><span class="p">[</span><span class="n">handle</span><span class="o">.</span><span class="n">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">hook</span>
    <span class="k">return</span> <span class="n">handle</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.register_parameter">
    <p>def <span class="ident">register_parameter</span>(</p><p>self, name, param)</p>
    </div>
    

    
  
    <div class="desc"><p>Adds a parameter to the module.</p>
<p>The parameter can be accessed as an attribute using given name.</p>
<p>Args:
    name (string): name of the parameter. The parameter can be accessed
        from this module using the given name
    parameter (Parameter): parameter to be added to the module.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.register_parameter', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.register_parameter" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">register_parameter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Adds a parameter to the module.</span>
<span class="sd">    The parameter can be accessed as an attribute using given name.</span>
<span class="sd">    Args:</span>
<span class="sd">        name (string): name of the parameter. The parameter can be accessed</span>
<span class="sd">            from this module using the given name</span>
<span class="sd">        parameter (Parameter): parameter to be added to the module.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="s1">&#39;_parameters&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
            <span class="s2">&quot;cannot assign parameter before Module.__init__() call&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;attribute &#39;{}&#39; already exists&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">param</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;cannot assign &#39;{}&#39; object to parameter &#39;{}&#39; &quot;</span>
                        <span class="s2">&quot;(torch.nn.Parameter or None required)&quot;</span>
                        <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">typename</span><span class="p">(</span><span class="n">param</span><span class="p">),</span> <span class="n">name</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">param</span><span class="o">.</span><span class="n">grad_fn</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Cannot assign non-leaf Variable to parameter &#39;{0}&#39;. Model &quot;</span>
            <span class="s2">&quot;parameters must be created explicitly. To express &#39;{0}&#39; &quot;</span>
            <span class="s2">&quot;as a function of another variable, compute the value in &quot;</span>
            <span class="s2">&quot;the forward() method.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.share_memory">
    <p>def <span class="ident">share_memory</span>(</p><p>self)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.share_memory', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.share_memory" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">share_memory</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">share_memory_</span><span class="p">())</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.state_dict">
    <p>def <span class="ident">state_dict</span>(</p><p>self, destination=None, prefix=&#39;&#39;, keep_vars=False)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns a dictionary containing a whole state of the module.</p>
<p>Both parameters and persistent buffers (e.g. running averages) are
included. Keys are corresponding parameter and buffer names.</p>
<p>When keep_vars is <code>True</code>, it returns a Variable for each parameter
(rather than a Tensor).</p>
<p>Args:
    destination (dict, optional):
        if not None, the return dictionary is stored into destination.
        Default: None
    prefix (string, optional): Adds a prefix to the key (name) of every
        parameter and buffer in the result dictionary. Default: ''
    keep_vars (bool, optional): if <code>True</code>, returns a Variable for each
        parameter. If <code>False</code>, returns a Tensor for each parameter.
        Default: <code>False</code></p>
<p>Returns:
    dict:
        a dictionary containing a whole state of the module</p>
<p>Example:
    &gt;&gt;&gt; module.state_dict().keys()
    ['bias', 'weight']</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.state_dict', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.state_dict" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">destination</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">keep_vars</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a dictionary containing a whole state of the module.</span>
<span class="sd">    Both parameters and persistent buffers (e.g. running averages) are</span>
<span class="sd">    included. Keys are corresponding parameter and buffer names.</span>
<span class="sd">    When keep_vars is ``True``, it returns a Variable for each parameter</span>
<span class="sd">    (rather than a Tensor).</span>
<span class="sd">    Args:</span>
<span class="sd">        destination (dict, optional):</span>
<span class="sd">            if not None, the return dictionary is stored into destination.</span>
<span class="sd">            Default: None</span>
<span class="sd">        prefix (string, optional): Adds a prefix to the key (name) of every</span>
<span class="sd">            parameter and buffer in the result dictionary. Default: &#39;&#39;</span>
<span class="sd">        keep_vars (bool, optional): if ``True``, returns a Variable for each</span>
<span class="sd">            parameter. If ``False``, returns a Tensor for each parameter.</span>
<span class="sd">            Default: ``False``</span>
<span class="sd">    Returns:</span>
<span class="sd">        dict:</span>
<span class="sd">            a dictionary containing a whole state of the module</span>
<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; module.state_dict().keys()</span>
<span class="sd">        [&#39;bias&#39;, &#39;weight&#39;]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">destination</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">destination</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">param</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">destination</span><span class="p">[</span><span class="n">prefix</span> <span class="o">+</span> <span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span> <span class="k">if</span> <span class="n">keep_vars</span> <span class="k">else</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">buf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_buffers</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">buf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">destination</span><span class="p">[</span><span class="n">prefix</span> <span class="o">+</span> <span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">buf</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">module</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">module</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(</span><span class="n">destination</span><span class="p">,</span> <span class="n">prefix</span> <span class="o">+</span> <span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">keep_vars</span><span class="o">=</span><span class="n">keep_vars</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">destination</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.train">
    <p>def <span class="ident">train</span>(</p><p>self, mode=True)</p>
    </div>
    

    
  
    <div class="desc"><p>Sets the module in training mode.</p>
<p>This has any effect only on modules such as Dropout or BatchNorm.</p>
<p>Returns:
    Module: self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.train', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.train" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets the module in training mode.</span>
<span class="sd">    This has any effect only on modules such as Dropout or BatchNorm.</span>
<span class="sd">    Returns:</span>
<span class="sd">        Module: self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="o">=</span> <span class="n">mode</span>
    <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">():</span>
        <span class="n">module</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.type">
    <p>def <span class="ident">type</span>(</p><p>self, dst_type)</p>
    </div>
    

    
  
    <div class="desc"><p>Casts all parameters and buffers to dst_type.</p>
<p>Arguments:
    dst_type (type or string): the desired type</p>
<p>Returns:
    Module: self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.type', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.type" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">type</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dst_type</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Casts all parameters and buffers to dst_type.</span>
<span class="sd">    Arguments:</span>
<span class="sd">        dst_type (type or string): the desired type</span>
<span class="sd">    Returns:</span>
<span class="sd">        Module: self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">dst_type</span><span class="p">))</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassification.zero_grad">
    <p>def <span class="ident">zero_grad</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Sets gradients of all model parameters to zero.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassification.zero_grad', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassification.zero_grad" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets gradients of all model parameters to zero.&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">volatile</span><span class="p">:</span>
                <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span>
                <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">new</span><span class="p">()</span><span class="o">.</span><span class="n">resize_as_</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">zero_</span><span class="p">())</span>
</pre></div>

  </div>
</div>

  </div>
  
          <h3>Instance variables</h3>
            <div class="item">
            <p id="noxer.nn.GRUClassification.ffnn" class="name">var <span class="ident">ffnn</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="noxer.nn.GRUClassification.rnn" class="name">var <span class="ident">rnn</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
      </div>
      </div>
      
      <div class="item">
      <p id="noxer.nn.GRUClassifier" class="name">class <span class="ident">GRUClassifier</span></p>
      
  
    <div class="desc"><p>Estimator with one dimensional convolutional neural network.</p>
<h2>Parameters</h2>
<p>For any parameters not listed, see PTLClassifierBase.</p>
<p>n_layers: int &gt; 0
    Number of layers in the NN</p>
<p>n_neurons: int &gt; 0
    Number of neurons in every layer</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassifier', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassifier" class="source">
    <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">GRUClassifier</span><span class="p">(</span><span class="n">PTLClassifierBase</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Estimator with one dimensional convolutional neural network.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    For any parameters not listed, see PTLClassifierBase.</span>

<span class="sd">    n_layers: int &gt; 0</span>
<span class="sd">        Number of layers in the NN</span>

<span class="sd">    n_neurons: int &gt; 0</span>
<span class="sd">        Number of neurons in every layer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
                 <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GRUClassifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span> <span class="o">=</span> <span class="n">n_neurons</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>

    <span class="k">def</span> <span class="nf">make_architecture</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        See PTLBase.make_architecture for explanations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">net</span> <span class="o">=</span> <span class="n">GRUClassification</span><span class="p">(</span>
            <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">y</span><span class="p">)),</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">net</span>
</pre></div>

  </div>
</div>


      <div class="class">
          <h3>Ancestors (in MRO)</h3>
          <ul class="class_list">
          <li><a href="#noxer.nn.GRUClassifier">GRUClassifier</a></li>
          <li><a href="#noxer.nn.PTLClassifierBase">PTLClassifierBase</a></li>
          <li><a href="#noxer.nn.PTLBase">PTLBase</a></li>
          <li>sklearn.base.BaseEstimator</li>
          <li>sklearn.base.ClassifierMixin</li>
          <li>builtins.object</li>
          </ul>
          <h3>Static methods</h3>
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassifier.__init__">
    <p>def <span class="ident">__init__</span>(</p><p>self, n_layers=1, n_neurons=32, dropout=None, epochs=10, batch_size=256, alpha=0.001, beta1=0.9, beta2=0.999)</p>
    </div>
    

    
  
    <div class="desc"><p>Initialize self.  See help(type(self)) for accurate signature.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassifier.__init__', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassifier.__init__" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
             <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">GRUClassifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span> <span class="o">=</span> <span class="n">n_neurons</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassifier.fit">
    <p>def <span class="ident">fit</span>(</p><p>self, X, y)</p>
    </div>
    

    
  
    <div class="desc"><p>Trains a classifier on provided data.</p>
<h2>Parameters</h2>
<p>X: iterable of size n_samples
    Representation of dataset.</p>
<p>y: iterable of size n_samples
    Representation of classes</p>
<h2>Return</h2>
<p>self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassifier.fit', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassifier.fit" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Trains a classifier on provided data.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X: iterable of size n_samples</span>
<span class="sd">        Representation of dataset.</span>
<span class="sd">    y: iterable of size n_samples</span>
<span class="sd">        Representation of classes</span>
<span class="sd">    Return</span>
<span class="sd">    ------</span>
<span class="sd">    self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># encode outputs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
    <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">PTLClassifierBase</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassifier.get_params">
    <p>def <span class="ident">get_params</span>(</p><p>self, deep=True)</p>
    </div>
    

    
  
    <div class="desc"><p>Get parameters for this estimator.</p>
<h2>Parameters</h2>
<p>deep : boolean, optional
    If True, will return the parameters for this estimator and
    contained subobjects that are estimators.</p>
<h2>Returns</h2>
<p>params : mapping of string to any
    Parameter names mapped to their values.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassifier.get_params', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassifier.get_params" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get parameters for this estimator.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    deep : boolean, optional</span>
<span class="sd">        If True, will return the parameters for this estimator and</span>
<span class="sd">        contained subobjects that are estimators.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    params : mapping of string to any</span>
<span class="sd">        Parameter names mapped to their values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">out</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_param_names</span><span class="p">():</span>
        <span class="c1"># We need deprecation warnings to always be on in order to</span>
        <span class="c1"># catch deprecated param values.</span>
        <span class="c1"># This is set in utils/__init__.py but it gets overwritten</span>
        <span class="c1"># when running under python3 somehow.</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;always&quot;</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">(</span><span class="n">record</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">w</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="ow">and</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">category</span> <span class="o">==</span> <span class="ne">DeprecationWarning</span><span class="p">:</span>
                <span class="c1"># if the parameter is deprecated, don&#39;t show it</span>
                <span class="k">continue</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">filters</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># XXX: should we rather test if instance of estimator?</span>
        <span class="k">if</span> <span class="n">deep</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s1">&#39;get_params&#39;</span><span class="p">):</span>
            <span class="n">deep_items</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="n">out</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="n">key</span> <span class="o">+</span> <span class="s1">&#39;__&#39;</span> <span class="o">+</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">deep_items</span><span class="p">)</span>
        <span class="n">out</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
    <span class="k">return</span> <span class="n">out</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassifier.make_architecture">
    <p>def <span class="ident">make_architecture</span>(</p><p>self, X, y)</p>
    </div>
    

    
  
    <div class="desc"><p>See PTLBase.make_architecture for explanations.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassifier.make_architecture', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassifier.make_architecture" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">make_architecture</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    See PTLBase.make_architecture for explanations.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">GRUClassification</span><span class="p">(</span>
        <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">y</span><span class="p">)),</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span>
        <span class="n">dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">net</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassifier.predict">
    <p>def <span class="ident">predict</span>(</p><p>self, X)</p>
    </div>
    

    
  
    <div class="desc"><p>Estimate output classes.</p>
<h2>Parameters</h2>
<p>X: iterable of size n_samples
    Representation of inputs to classify.</p>
<h2>Return</h2>
<p>y: iterable of size n_samples
    Representation of classes</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassifier.predict', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassifier.predict" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Estimate output classes.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X: iterable of size n_samples</span>
<span class="sd">        Representation of inputs to classify.</span>
<span class="sd">    Return</span>
<span class="sd">    ------</span>
<span class="sd">    y: iterable of size n_samples</span>
<span class="sd">        Representation of classes</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">yp</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">PTLClassifierBase</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">yp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">yp</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">yp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">yp</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">yp</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassifier.score">
    <p>def <span class="ident">score</span>(</p><p>self, X, y, sample_weight=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h2>Parameters</h2>
<p>X : array-like, shape = (n_samples, n_features)
    Test samples.</p>
<p>y : array-like, shape = (n_samples) or (n_samples, n_outputs)
    True labels for X.</p>
<p>sample_weight : array-like, shape = [n_samples], optional
    Sample weights.</p>
<h2>Returns</h2>
<p>score : float
    Mean accuracy of self.predict(X) wrt. y.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassifier.score', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassifier.score" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the mean accuracy on the given test data and labels.</span>
<span class="sd">    In multi-label classification, this is the subset accuracy</span>
<span class="sd">    which is a harsh metric since you require for each sample that</span>
<span class="sd">    each label set be correctly predicted.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array-like, shape = (n_samples, n_features)</span>
<span class="sd">        Test samples.</span>
<span class="sd">    y : array-like, shape = (n_samples) or (n_samples, n_outputs)</span>
<span class="sd">        True labels for X.</span>
<span class="sd">    sample_weight : array-like, shape = [n_samples], optional</span>
<span class="sd">        Sample weights.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score : float</span>
<span class="sd">        Mean accuracy of self.predict(X) wrt. y.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
    <span class="k">return</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.GRUClassifier.set_params">
    <p>def <span class="ident">set_params</span>(</p><p>self, **params)</p>
    </div>
    

    
  
    <div class="desc"><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2>Returns</h2>
<p>self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.GRUClassifier.set_params', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.GRUClassifier.set_params" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Set the parameters of this estimator.</span>
<span class="sd">    The method works on simple estimators as well as on nested objects</span>
<span class="sd">    (such as pipelines). The latter have parameters of the form</span>
<span class="sd">    ``&lt;component&gt;__&lt;parameter&gt;`` so that it&#39;s possible to update each</span>
<span class="sd">    component of a nested object.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">params</span><span class="p">:</span>
        <span class="c1"># Simple optimization to gain speed (inspect is slow)</span>
        <span class="k">return</span> <span class="bp">self</span>
    <span class="n">valid_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_params</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">nested_params</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">dict</span><span class="p">)</span>  <span class="c1"># grouped by prefix</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">key</span><span class="p">,</span> <span class="n">delim</span><span class="p">,</span> <span class="n">sub_key</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">partition</span><span class="p">(</span><span class="s1">&#39;__&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_params</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Invalid parameter </span><span class="si">%s</span><span class="s1"> for estimator </span><span class="si">%s</span><span class="s1">. &#39;</span>
                             <span class="s1">&#39;Check the list of available parameters &#39;</span>
                             <span class="s1">&#39;with `estimator.get_params().keys()`.&#39;</span> <span class="o">%</span>
                             <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">delim</span><span class="p">:</span>
            <span class="n">nested_params</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">sub_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">sub_params</span> <span class="ow">in</span> <span class="n">nested_params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">valid_params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">sub_params</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>

  </div>
</div>

  </div>
  
          <h3>Instance variables</h3>
            <div class="item">
            <p id="noxer.nn.GRUClassifier.dropout" class="name">var <span class="ident">dropout</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="noxer.nn.GRUClassifier.n_layers" class="name">var <span class="ident">n_layers</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="noxer.nn.GRUClassifier.n_neurons" class="name">var <span class="ident">n_neurons</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
      </div>
      </div>
      
      <div class="item">
      <p id="noxer.nn.MLPClassifier" class="name">class <span class="ident">MLPClassifier</span></p>
      
  
    <div class="desc"><p>Estimator with Feed Forward Neural Network.</p>
<h2>Parameters</h2>
<p>For any parameters not listed, see PTLClassifierBase.</p>
<p>n_layers: int &gt; 0
    Number of layers in the NN</p>
<p>n_neurons: int &gt; 0
    Number of neurons in every layer</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.MLPClassifier', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.MLPClassifier" class="source">
    <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">MLPClassifier</span><span class="p">(</span><span class="n">PTLClassifierBase</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Estimator with Feed Forward Neural Network.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    For any parameters not listed, see PTLClassifierBase.</span>

<span class="sd">    n_layers: int &gt; 0</span>
<span class="sd">        Number of layers in the NN</span>

<span class="sd">    n_neurons: int &gt; 0</span>
<span class="sd">        Number of neurons in every layer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
                 <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MLPClassifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span> <span class="o">=</span> <span class="n">n_neurons</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>

    <span class="k">def</span> <span class="nf">make_architecture</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        See PTLBase.make_architecture for explanations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">net</span> <span class="o">=</span> <span class="n">FFNNClassificationNN</span><span class="p">(</span>
            <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">y</span><span class="p">)),</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">net</span>
</pre></div>

  </div>
</div>


      <div class="class">
          <h3>Ancestors (in MRO)</h3>
          <ul class="class_list">
          <li><a href="#noxer.nn.MLPClassifier">MLPClassifier</a></li>
          <li><a href="#noxer.nn.PTLClassifierBase">PTLClassifierBase</a></li>
          <li><a href="#noxer.nn.PTLBase">PTLBase</a></li>
          <li>sklearn.base.BaseEstimator</li>
          <li>sklearn.base.ClassifierMixin</li>
          <li>builtins.object</li>
          </ul>
          <h3>Static methods</h3>
            
  <div class="item">
    <div class="name def" id="noxer.nn.MLPClassifier.__init__">
    <p>def <span class="ident">__init__</span>(</p><p>self, dropout=None, n_layers=1, n_neurons=32, epochs=10, batch_size=256, alpha=0.001, beta1=0.9, beta2=0.999)</p>
    </div>
    

    
  
    <div class="desc"><p>Initialize self.  See help(type(self)) for accurate signature.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.MLPClassifier.__init__', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.MLPClassifier.__init__" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
             <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MLPClassifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span> <span class="o">=</span> <span class="n">n_neurons</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.MLPClassifier.fit">
    <p>def <span class="ident">fit</span>(</p><p>self, X, y)</p>
    </div>
    

    
  
    <div class="desc"><p>Trains a classifier on provided data.</p>
<h2>Parameters</h2>
<p>X: iterable of size n_samples
    Representation of dataset.</p>
<p>y: iterable of size n_samples
    Representation of classes</p>
<h2>Return</h2>
<p>self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.MLPClassifier.fit', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.MLPClassifier.fit" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Trains a classifier on provided data.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X: iterable of size n_samples</span>
<span class="sd">        Representation of dataset.</span>
<span class="sd">    y: iterable of size n_samples</span>
<span class="sd">        Representation of classes</span>
<span class="sd">    Return</span>
<span class="sd">    ------</span>
<span class="sd">    self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># encode outputs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
    <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">PTLClassifierBase</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.MLPClassifier.get_params">
    <p>def <span class="ident">get_params</span>(</p><p>self, deep=True)</p>
    </div>
    

    
  
    <div class="desc"><p>Get parameters for this estimator.</p>
<h2>Parameters</h2>
<p>deep : boolean, optional
    If True, will return the parameters for this estimator and
    contained subobjects that are estimators.</p>
<h2>Returns</h2>
<p>params : mapping of string to any
    Parameter names mapped to their values.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.MLPClassifier.get_params', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.MLPClassifier.get_params" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get parameters for this estimator.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    deep : boolean, optional</span>
<span class="sd">        If True, will return the parameters for this estimator and</span>
<span class="sd">        contained subobjects that are estimators.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    params : mapping of string to any</span>
<span class="sd">        Parameter names mapped to their values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">out</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_param_names</span><span class="p">():</span>
        <span class="c1"># We need deprecation warnings to always be on in order to</span>
        <span class="c1"># catch deprecated param values.</span>
        <span class="c1"># This is set in utils/__init__.py but it gets overwritten</span>
        <span class="c1"># when running under python3 somehow.</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;always&quot;</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">(</span><span class="n">record</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">w</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="ow">and</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">category</span> <span class="o">==</span> <span class="ne">DeprecationWarning</span><span class="p">:</span>
                <span class="c1"># if the parameter is deprecated, don&#39;t show it</span>
                <span class="k">continue</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">filters</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># XXX: should we rather test if instance of estimator?</span>
        <span class="k">if</span> <span class="n">deep</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s1">&#39;get_params&#39;</span><span class="p">):</span>
            <span class="n">deep_items</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="n">out</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="n">key</span> <span class="o">+</span> <span class="s1">&#39;__&#39;</span> <span class="o">+</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">deep_items</span><span class="p">)</span>
        <span class="n">out</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
    <span class="k">return</span> <span class="n">out</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.MLPClassifier.make_architecture">
    <p>def <span class="ident">make_architecture</span>(</p><p>self, X, y)</p>
    </div>
    

    
  
    <div class="desc"><p>See PTLBase.make_architecture for explanations.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.MLPClassifier.make_architecture', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.MLPClassifier.make_architecture" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">make_architecture</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    See PTLBase.make_architecture for explanations.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">FFNNClassificationNN</span><span class="p">(</span>
        <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">y</span><span class="p">)),</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span>
        <span class="n">dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">net</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.MLPClassifier.predict">
    <p>def <span class="ident">predict</span>(</p><p>self, X)</p>
    </div>
    

    
  
    <div class="desc"><p>Estimate output classes.</p>
<h2>Parameters</h2>
<p>X: iterable of size n_samples
    Representation of inputs to classify.</p>
<h2>Return</h2>
<p>y: iterable of size n_samples
    Representation of classes</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.MLPClassifier.predict', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.MLPClassifier.predict" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Estimate output classes.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X: iterable of size n_samples</span>
<span class="sd">        Representation of inputs to classify.</span>
<span class="sd">    Return</span>
<span class="sd">    ------</span>
<span class="sd">    y: iterable of size n_samples</span>
<span class="sd">        Representation of classes</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">yp</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">PTLClassifierBase</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">yp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">yp</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">yp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">yp</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">yp</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.MLPClassifier.score">
    <p>def <span class="ident">score</span>(</p><p>self, X, y, sample_weight=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h2>Parameters</h2>
<p>X : array-like, shape = (n_samples, n_features)
    Test samples.</p>
<p>y : array-like, shape = (n_samples) or (n_samples, n_outputs)
    True labels for X.</p>
<p>sample_weight : array-like, shape = [n_samples], optional
    Sample weights.</p>
<h2>Returns</h2>
<p>score : float
    Mean accuracy of self.predict(X) wrt. y.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.MLPClassifier.score', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.MLPClassifier.score" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the mean accuracy on the given test data and labels.</span>
<span class="sd">    In multi-label classification, this is the subset accuracy</span>
<span class="sd">    which is a harsh metric since you require for each sample that</span>
<span class="sd">    each label set be correctly predicted.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array-like, shape = (n_samples, n_features)</span>
<span class="sd">        Test samples.</span>
<span class="sd">    y : array-like, shape = (n_samples) or (n_samples, n_outputs)</span>
<span class="sd">        True labels for X.</span>
<span class="sd">    sample_weight : array-like, shape = [n_samples], optional</span>
<span class="sd">        Sample weights.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score : float</span>
<span class="sd">        Mean accuracy of self.predict(X) wrt. y.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
    <span class="k">return</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.MLPClassifier.set_params">
    <p>def <span class="ident">set_params</span>(</p><p>self, **params)</p>
    </div>
    

    
  
    <div class="desc"><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2>Returns</h2>
<p>self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.MLPClassifier.set_params', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.MLPClassifier.set_params" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Set the parameters of this estimator.</span>
<span class="sd">    The method works on simple estimators as well as on nested objects</span>
<span class="sd">    (such as pipelines). The latter have parameters of the form</span>
<span class="sd">    ``&lt;component&gt;__&lt;parameter&gt;`` so that it&#39;s possible to update each</span>
<span class="sd">    component of a nested object.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">params</span><span class="p">:</span>
        <span class="c1"># Simple optimization to gain speed (inspect is slow)</span>
        <span class="k">return</span> <span class="bp">self</span>
    <span class="n">valid_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_params</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">nested_params</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">dict</span><span class="p">)</span>  <span class="c1"># grouped by prefix</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">key</span><span class="p">,</span> <span class="n">delim</span><span class="p">,</span> <span class="n">sub_key</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">partition</span><span class="p">(</span><span class="s1">&#39;__&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_params</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Invalid parameter </span><span class="si">%s</span><span class="s1"> for estimator </span><span class="si">%s</span><span class="s1">. &#39;</span>
                             <span class="s1">&#39;Check the list of available parameters &#39;</span>
                             <span class="s1">&#39;with `estimator.get_params().keys()`.&#39;</span> <span class="o">%</span>
                             <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">delim</span><span class="p">:</span>
            <span class="n">nested_params</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">sub_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">sub_params</span> <span class="ow">in</span> <span class="n">nested_params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">valid_params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">sub_params</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>

  </div>
</div>

  </div>
  
          <h3>Instance variables</h3>
            <div class="item">
            <p id="noxer.nn.MLPClassifier.dropout" class="name">var <span class="ident">dropout</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="noxer.nn.MLPClassifier.n_layers" class="name">var <span class="ident">n_layers</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="noxer.nn.MLPClassifier.n_neurons" class="name">var <span class="ident">n_neurons</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
      </div>
      </div>
      
      <div class="item">
      <p id="noxer.nn.PTLBase" class="name">class <span class="ident">PTLBase</span></p>
      
  
    <div class="desc"><p>A base class for learning algorithms with pytorch.</p>
<h2>Parameters</h2>
<p>epochs: int &gt; 0
    Number of epochs to train neural network for.</p>
<p>batch_size: int &gt; 0
    Size of subsample of dataset to use to approximate the gradient in
    stochatic gradient descent procedure.</p>
<p>alpha: float &gt; 0
    Learning rate. Tunes the amount of update done after processing of
    single batch size.</p>
<p>beta1: float 0.0 &lt; x &lt; 1.0
    Beta 1 parameter of Adam stochastic gradient descent algorithm.</p>
<p>beta2: float 0.0 &lt; x &lt; 1.0
    Beta 2 parameter of Adam stochastic gradient descent algorithm.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.PTLBase', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.PTLBase" class="source">
    <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">PTLBase</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A base class for learning algorithms with pytorch.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    epochs: int &gt; 0</span>
<span class="sd">        Number of epochs to train neural network for.</span>

<span class="sd">    batch_size: int &gt; 0</span>
<span class="sd">        Size of subsample of dataset to use to approximate the gradient in</span>
<span class="sd">        stochatic gradient descent procedure.</span>

<span class="sd">    alpha: float &gt; 0</span>
<span class="sd">        Learning rate. Tunes the amount of update done after processing of</span>
<span class="sd">        single batch size.</span>

<span class="sd">    beta1: float 0.0 &lt; x &lt; 1.0</span>
<span class="sd">        Beta 1 parameter of Adam stochastic gradient descent algorithm.</span>

<span class="sd">    beta2: float 0.0 &lt; x &lt; 1.0</span>
<span class="sd">        Beta 2 parameter of Adam stochastic gradient descent algorithm.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="n">epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">=</span> <span class="n">beta1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span> <span class="o">=</span> <span class="n">beta2</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">make_architecture</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Should return nn.Module instance, which represents architecture</span>
<span class="sd">        of the neural network.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        X: iterable of size n_samples</span>
<span class="sd">            Representation of dataset.</span>

<span class="sd">        y: iterable of size n_samples</span>
<span class="sd">            Representation of output</span>

<span class="sd">        Return</span>
<span class="sd">        ------</span>
<span class="sd">        net: an instance of a neural network to be trained.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">criterion</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Trains a neural network on provided data.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        X: iterable of size n_samples</span>
<span class="sd">            Representation of dataset.</span>

<span class="sd">        y: iterable of size n_samples</span>
<span class="sd">            Representation of output</span>

<span class="sd">        criterion: callable with 2 arguments, possibly a nn._Loss instance.</span>
<span class="sd">            Cost function to minimize.</span>

<span class="sd">        Return</span>
<span class="sd">        ------</span>
<span class="sd">        self</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_X_y</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">allow_nd</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_architecture</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span><span class="p">))</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TensorDataset</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># this creates mixed batches</span>
        <span class="n">trainloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">epochs</span><span class="p">):</span>  <span class="c1"># loop over the dataset multiple times</span>

            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">trainloader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
                <span class="c1"># get the inputs</span>
                <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>

                <span class="c1"># wrap them in Variable</span>
                <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="n">Variable</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

                <span class="c1"># zero the parameter gradients</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

                <span class="c1"># forward + backward + optimize</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Make estimation with trained neural network.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        X: iterable of size n_samples</span>
<span class="sd">            Representation of inputs. Should be consistent with</span>
<span class="sd">            inputs in the training dataset.</span>

<span class="sd">        Return</span>
<span class="sd">        ------</span>
<span class="sd">        X: iterable of size n_samples</span>
<span class="sd">            Representation of estimated outputs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;The model is not fit. Did you forget to call the fit method on a dataset?&quot;</span><span class="p">)</span>

        <span class="n">X</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">volatile</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">yp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">yp</span>
</pre></div>

  </div>
</div>


      <div class="class">
          <h3>Ancestors (in MRO)</h3>
          <ul class="class_list">
          <li><a href="#noxer.nn.PTLBase">PTLBase</a></li>
          <li>sklearn.base.BaseEstimator</li>
          <li>builtins.object</li>
          </ul>
          <h3>Static methods</h3>
            
  <div class="item">
    <div class="name def" id="noxer.nn.PTLBase.__init__">
    <p>def <span class="ident">__init__</span>(</p><p>self, epochs=10, batch_size=256, alpha=0.001, beta1=0.9, beta2=0.999)</p>
    </div>
    

    
  
    <div class="desc"><p>Initialize self.  See help(type(self)) for accurate signature.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.PTLBase.__init__', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.PTLBase.__init__" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="n">epochs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">=</span> <span class="n">beta1</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span> <span class="o">=</span> <span class="n">beta2</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="bp">None</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.PTLBase.fit">
    <p>def <span class="ident">fit</span>(</p><p>self, X, y, criterion)</p>
    </div>
    

    
  
    <div class="desc"><p>Trains a neural network on provided data.</p>
<h2>Parameters</h2>
<p>X: iterable of size n_samples
    Representation of dataset.</p>
<p>y: iterable of size n_samples
    Representation of output</p>
<p>criterion: callable with 2 arguments, possibly a nn._Loss instance.
    Cost function to minimize.</p>
<h2>Return</h2>
<p>self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.PTLBase.fit', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.PTLBase.fit" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">criterion</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Trains a neural network on provided data.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X: iterable of size n_samples</span>
<span class="sd">        Representation of dataset.</span>
<span class="sd">    y: iterable of size n_samples</span>
<span class="sd">        Representation of output</span>
<span class="sd">    criterion: callable with 2 arguments, possibly a nn._Loss instance.</span>
<span class="sd">        Cost function to minimize.</span>
<span class="sd">    Return</span>
<span class="sd">    ------</span>
<span class="sd">    self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">check_X_y</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">allow_nd</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_architecture</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span><span class="p">))</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TensorDataset</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="c1"># this creates mixed batches</span>
    <span class="n">trainloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span>
    <span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">epochs</span><span class="p">):</span>  <span class="c1"># loop over the dataset multiple times</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">trainloader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
            <span class="c1"># get the inputs</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
            <span class="c1"># wrap them in Variable</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="n">Variable</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
            <span class="c1"># zero the parameter gradients</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="c1"># forward + backward + optimize</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.PTLBase.get_params">
    <p>def <span class="ident">get_params</span>(</p><p>self, deep=True)</p>
    </div>
    

    
  
    <div class="desc"><p>Get parameters for this estimator.</p>
<h2>Parameters</h2>
<p>deep : boolean, optional
    If True, will return the parameters for this estimator and
    contained subobjects that are estimators.</p>
<h2>Returns</h2>
<p>params : mapping of string to any
    Parameter names mapped to their values.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.PTLBase.get_params', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.PTLBase.get_params" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get parameters for this estimator.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    deep : boolean, optional</span>
<span class="sd">        If True, will return the parameters for this estimator and</span>
<span class="sd">        contained subobjects that are estimators.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    params : mapping of string to any</span>
<span class="sd">        Parameter names mapped to their values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">out</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_param_names</span><span class="p">():</span>
        <span class="c1"># We need deprecation warnings to always be on in order to</span>
        <span class="c1"># catch deprecated param values.</span>
        <span class="c1"># This is set in utils/__init__.py but it gets overwritten</span>
        <span class="c1"># when running under python3 somehow.</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;always&quot;</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">(</span><span class="n">record</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">w</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="ow">and</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">category</span> <span class="o">==</span> <span class="ne">DeprecationWarning</span><span class="p">:</span>
                <span class="c1"># if the parameter is deprecated, don&#39;t show it</span>
                <span class="k">continue</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">filters</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># XXX: should we rather test if instance of estimator?</span>
        <span class="k">if</span> <span class="n">deep</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s1">&#39;get_params&#39;</span><span class="p">):</span>
            <span class="n">deep_items</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="n">out</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="n">key</span> <span class="o">+</span> <span class="s1">&#39;__&#39;</span> <span class="o">+</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">deep_items</span><span class="p">)</span>
        <span class="n">out</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
    <span class="k">return</span> <span class="n">out</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.PTLBase.make_architecture">
    <p>def <span class="ident">make_architecture</span>(</p><p>self, X, y)</p>
    </div>
    

    
  
    <div class="desc"><p>Should return nn.Module instance, which represents architecture
of the neural network.</p>
<h2>Parameters</h2>
<p>X: iterable of size n_samples
    Representation of dataset.</p>
<p>y: iterable of size n_samples
    Representation of output</p>
<h2>Return</h2>
<p>net: an instance of a neural network to be trained.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.PTLBase.make_architecture', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.PTLBase.make_architecture" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@abstractmethod</span>
<span class="k">def</span> <span class="nf">make_architecture</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Should return nn.Module instance, which represents architecture</span>
<span class="sd">    of the neural network.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X: iterable of size n_samples</span>
<span class="sd">        Representation of dataset.</span>
<span class="sd">    y: iterable of size n_samples</span>
<span class="sd">        Representation of output</span>
<span class="sd">    Return</span>
<span class="sd">    ------</span>
<span class="sd">    net: an instance of a neural network to be trained.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">pass</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.PTLBase.predict">
    <p>def <span class="ident">predict</span>(</p><p>self, X)</p>
    </div>
    

    
  
    <div class="desc"><p>Make estimation with trained neural network.</p>
<h2>Parameters</h2>
<p>X: iterable of size n_samples
    Representation of inputs. Should be consistent with
    inputs in the training dataset.</p>
<h2>Return</h2>
<p>X: iterable of size n_samples
    Representation of estimated outputs.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.PTLBase.predict', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.PTLBase.predict" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Make estimation with trained neural network.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X: iterable of size n_samples</span>
<span class="sd">        Representation of inputs. Should be consistent with</span>
<span class="sd">        inputs in the training dataset.</span>
<span class="sd">    Return</span>
<span class="sd">    ------</span>
<span class="sd">    X: iterable of size n_samples</span>
<span class="sd">        Representation of estimated outputs.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;The model is not fit. Did you forget to call the fit method on a dataset?&quot;</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">volatile</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">yp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">yp</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.PTLBase.set_params">
    <p>def <span class="ident">set_params</span>(</p><p>self, **params)</p>
    </div>
    

    
  
    <div class="desc"><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2>Returns</h2>
<p>self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.PTLBase.set_params', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.PTLBase.set_params" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Set the parameters of this estimator.</span>
<span class="sd">    The method works on simple estimators as well as on nested objects</span>
<span class="sd">    (such as pipelines). The latter have parameters of the form</span>
<span class="sd">    ``&lt;component&gt;__&lt;parameter&gt;`` so that it&#39;s possible to update each</span>
<span class="sd">    component of a nested object.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">params</span><span class="p">:</span>
        <span class="c1"># Simple optimization to gain speed (inspect is slow)</span>
        <span class="k">return</span> <span class="bp">self</span>
    <span class="n">valid_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_params</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">nested_params</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">dict</span><span class="p">)</span>  <span class="c1"># grouped by prefix</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">key</span><span class="p">,</span> <span class="n">delim</span><span class="p">,</span> <span class="n">sub_key</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">partition</span><span class="p">(</span><span class="s1">&#39;__&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_params</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Invalid parameter </span><span class="si">%s</span><span class="s1"> for estimator </span><span class="si">%s</span><span class="s1">. &#39;</span>
                             <span class="s1">&#39;Check the list of available parameters &#39;</span>
                             <span class="s1">&#39;with `estimator.get_params().keys()`.&#39;</span> <span class="o">%</span>
                             <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">delim</span><span class="p">:</span>
            <span class="n">nested_params</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">sub_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">sub_params</span> <span class="ow">in</span> <span class="n">nested_params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">valid_params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">sub_params</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>

  </div>
</div>

  </div>
  
          <h3>Instance variables</h3>
            <div class="item">
            <p id="noxer.nn.PTLBase.alpha" class="name">var <span class="ident">alpha</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="noxer.nn.PTLBase.batch_size" class="name">var <span class="ident">batch_size</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="noxer.nn.PTLBase.beta1" class="name">var <span class="ident">beta1</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="noxer.nn.PTLBase.beta2" class="name">var <span class="ident">beta2</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="noxer.nn.PTLBase.epochs" class="name">var <span class="ident">epochs</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="noxer.nn.PTLBase.net" class="name">var <span class="ident">net</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
      </div>
      </div>
      
      <div class="item">
      <p id="noxer.nn.PTLClassifierBase" class="name">class <span class="ident">PTLClassifierBase</span></p>
      
  
    <div class="desc"><p>A base class for learning classifiers with pytorch.</p>
<h2>Parameters</h2>
<p>See parent classes for corresponding parameters.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.PTLClassifierBase', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.PTLClassifierBase" class="source">
    <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">PTLClassifierBase</span><span class="p">(</span><span class="n">PTLBase</span><span class="p">,</span> <span class="n">ClassifierMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A base class for learning classifiers with pytorch.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    See parent classes for corresponding parameters.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
                 <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PTLClassifierBase</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Trains a classifier on provided data.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        X: iterable of size n_samples</span>
<span class="sd">            Representation of dataset.</span>

<span class="sd">        y: iterable of size n_samples</span>
<span class="sd">            Representation of classes</span>

<span class="sd">        Return</span>
<span class="sd">        ------</span>
<span class="sd">        self</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># encode outputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PTLClassifierBase</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Estimate output classes.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X: iterable of size n_samples</span>
<span class="sd">            Representation of inputs to classify.</span>

<span class="sd">        Return</span>
<span class="sd">        ------</span>
<span class="sd">        y: iterable of size n_samples</span>
<span class="sd">            Representation of classes</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">yp</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">PTLClassifierBase</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">yp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">yp</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">yp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">yp</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">yp</span>
</pre></div>

  </div>
</div>


      <div class="class">
          <h3>Ancestors (in MRO)</h3>
          <ul class="class_list">
          <li><a href="#noxer.nn.PTLClassifierBase">PTLClassifierBase</a></li>
          <li><a href="#noxer.nn.PTLBase">PTLBase</a></li>
          <li>sklearn.base.BaseEstimator</li>
          <li>sklearn.base.ClassifierMixin</li>
          <li>builtins.object</li>
          </ul>
          <h3>Static methods</h3>
            
  <div class="item">
    <div class="name def" id="noxer.nn.PTLClassifierBase.__init__">
    <p>def <span class="ident">__init__</span>(</p><p>self, epochs=10, batch_size=256, alpha=0.001, beta1=0.9, beta2=0.999)</p>
    </div>
    

    
  
    <div class="desc"><p>Initialize self.  See help(type(self)) for accurate signature.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.PTLClassifierBase.__init__', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.PTLClassifierBase.__init__" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
             <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">PTLClassifierBase</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span> <span class="o">=</span> <span class="bp">None</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.PTLClassifierBase.fit">
    <p>def <span class="ident">fit</span>(</p><p>self, X, y)</p>
    </div>
    

    
  
    <div class="desc"><p>Trains a classifier on provided data.</p>
<h2>Parameters</h2>
<p>X: iterable of size n_samples
    Representation of dataset.</p>
<p>y: iterable of size n_samples
    Representation of classes</p>
<h2>Return</h2>
<p>self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.PTLClassifierBase.fit', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.PTLClassifierBase.fit" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Trains a classifier on provided data.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X: iterable of size n_samples</span>
<span class="sd">        Representation of dataset.</span>
<span class="sd">    y: iterable of size n_samples</span>
<span class="sd">        Representation of classes</span>
<span class="sd">    Return</span>
<span class="sd">    ------</span>
<span class="sd">    self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># encode outputs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
    <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">PTLClassifierBase</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.PTLClassifierBase.get_params">
    <p>def <span class="ident">get_params</span>(</p><p>self, deep=True)</p>
    </div>
    

    
  
    <div class="desc"><p>Get parameters for this estimator.</p>
<h2>Parameters</h2>
<p>deep : boolean, optional
    If True, will return the parameters for this estimator and
    contained subobjects that are estimators.</p>
<h2>Returns</h2>
<p>params : mapping of string to any
    Parameter names mapped to their values.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.PTLClassifierBase.get_params', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.PTLClassifierBase.get_params" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get parameters for this estimator.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    deep : boolean, optional</span>
<span class="sd">        If True, will return the parameters for this estimator and</span>
<span class="sd">        contained subobjects that are estimators.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    params : mapping of string to any</span>
<span class="sd">        Parameter names mapped to their values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">out</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_param_names</span><span class="p">():</span>
        <span class="c1"># We need deprecation warnings to always be on in order to</span>
        <span class="c1"># catch deprecated param values.</span>
        <span class="c1"># This is set in utils/__init__.py but it gets overwritten</span>
        <span class="c1"># when running under python3 somehow.</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;always&quot;</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">(</span><span class="n">record</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">w</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="ow">and</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">category</span> <span class="o">==</span> <span class="ne">DeprecationWarning</span><span class="p">:</span>
                <span class="c1"># if the parameter is deprecated, don&#39;t show it</span>
                <span class="k">continue</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">filters</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># XXX: should we rather test if instance of estimator?</span>
        <span class="k">if</span> <span class="n">deep</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s1">&#39;get_params&#39;</span><span class="p">):</span>
            <span class="n">deep_items</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="n">out</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="n">key</span> <span class="o">+</span> <span class="s1">&#39;__&#39;</span> <span class="o">+</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">deep_items</span><span class="p">)</span>
        <span class="n">out</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
    <span class="k">return</span> <span class="n">out</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.PTLClassifierBase.make_architecture">
    <p>def <span class="ident">make_architecture</span>(</p><p>self, X, y)</p>
    </div>
    

    
  
    <div class="desc"><p>Should return nn.Module instance, which represents architecture
of the neural network.</p>
<h2>Parameters</h2>
<p>X: iterable of size n_samples
    Representation of dataset.</p>
<p>y: iterable of size n_samples
    Representation of output</p>
<h2>Return</h2>
<p>net: an instance of a neural network to be trained.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.PTLClassifierBase.make_architecture', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.PTLClassifierBase.make_architecture" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@abstractmethod</span>
<span class="k">def</span> <span class="nf">make_architecture</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Should return nn.Module instance, which represents architecture</span>
<span class="sd">    of the neural network.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X: iterable of size n_samples</span>
<span class="sd">        Representation of dataset.</span>
<span class="sd">    y: iterable of size n_samples</span>
<span class="sd">        Representation of output</span>
<span class="sd">    Return</span>
<span class="sd">    ------</span>
<span class="sd">    net: an instance of a neural network to be trained.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">pass</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.PTLClassifierBase.predict">
    <p>def <span class="ident">predict</span>(</p><p>self, X)</p>
    </div>
    

    
  
    <div class="desc"><p>Estimate output classes.</p>
<h2>Parameters</h2>
<p>X: iterable of size n_samples
    Representation of inputs to classify.</p>
<h2>Return</h2>
<p>y: iterable of size n_samples
    Representation of classes</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.PTLClassifierBase.predict', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.PTLClassifierBase.predict" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Estimate output classes.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X: iterable of size n_samples</span>
<span class="sd">        Representation of inputs to classify.</span>
<span class="sd">    Return</span>
<span class="sd">    ------</span>
<span class="sd">    y: iterable of size n_samples</span>
<span class="sd">        Representation of classes</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">yp</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">PTLClassifierBase</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">yp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">yp</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">yp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">yp</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">yp</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.PTLClassifierBase.score">
    <p>def <span class="ident">score</span>(</p><p>self, X, y, sample_weight=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h2>Parameters</h2>
<p>X : array-like, shape = (n_samples, n_features)
    Test samples.</p>
<p>y : array-like, shape = (n_samples) or (n_samples, n_outputs)
    True labels for X.</p>
<p>sample_weight : array-like, shape = [n_samples], optional
    Sample weights.</p>
<h2>Returns</h2>
<p>score : float
    Mean accuracy of self.predict(X) wrt. y.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.PTLClassifierBase.score', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.PTLClassifierBase.score" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the mean accuracy on the given test data and labels.</span>
<span class="sd">    In multi-label classification, this is the subset accuracy</span>
<span class="sd">    which is a harsh metric since you require for each sample that</span>
<span class="sd">    each label set be correctly predicted.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array-like, shape = (n_samples, n_features)</span>
<span class="sd">        Test samples.</span>
<span class="sd">    y : array-like, shape = (n_samples) or (n_samples, n_outputs)</span>
<span class="sd">        True labels for X.</span>
<span class="sd">    sample_weight : array-like, shape = [n_samples], optional</span>
<span class="sd">        Sample weights.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score : float</span>
<span class="sd">        Mean accuracy of self.predict(X) wrt. y.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
    <span class="k">return</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="noxer.nn.PTLClassifierBase.set_params">
    <p>def <span class="ident">set_params</span>(</p><p>self, **params)</p>
    </div>
    

    
  
    <div class="desc"><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2>Returns</h2>
<p>self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-noxer.nn.PTLClassifierBase.set_params', this);">Show source &equiv;</a></p>
  <div id="source-noxer.nn.PTLClassifierBase.set_params" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Set the parameters of this estimator.</span>
<span class="sd">    The method works on simple estimators as well as on nested objects</span>
<span class="sd">    (such as pipelines). The latter have parameters of the form</span>
<span class="sd">    ``&lt;component&gt;__&lt;parameter&gt;`` so that it&#39;s possible to update each</span>
<span class="sd">    component of a nested object.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">params</span><span class="p">:</span>
        <span class="c1"># Simple optimization to gain speed (inspect is slow)</span>
        <span class="k">return</span> <span class="bp">self</span>
    <span class="n">valid_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_params</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">nested_params</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">dict</span><span class="p">)</span>  <span class="c1"># grouped by prefix</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">key</span><span class="p">,</span> <span class="n">delim</span><span class="p">,</span> <span class="n">sub_key</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">partition</span><span class="p">(</span><span class="s1">&#39;__&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_params</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Invalid parameter </span><span class="si">%s</span><span class="s1"> for estimator </span><span class="si">%s</span><span class="s1">. &#39;</span>
                             <span class="s1">&#39;Check the list of available parameters &#39;</span>
                             <span class="s1">&#39;with `estimator.get_params().keys()`.&#39;</span> <span class="o">%</span>
                             <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">delim</span><span class="p">:</span>
            <span class="n">nested_params</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">sub_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">sub_params</span> <span class="ow">in</span> <span class="n">nested_params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">valid_params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">sub_params</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>

  </div>
</div>

  </div>
  
          <h3>Instance variables</h3>
            <div class="item">
            <p id="noxer.nn.PTLClassifierBase.label_encoder" class="name">var <span class="ident">label_encoder</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
      </div>
      </div>

  </section>

    </article>
  <div class="clear"> </div>
  <footer id="footer">
    <p>
      Documentation generated by
      <a href="https://github.com/BurntSushi/pdoc">pdoc 0.3.2</a>
    </p>

    <p>pdoc is in the public domain with the
      <a href="http://unlicense.org">UNLICENSE</a></p>

    <p>Design by <a href="http://nadh.in">Kailash Nadh</a></p>
  </footer>
</div>
</body>
</html>
